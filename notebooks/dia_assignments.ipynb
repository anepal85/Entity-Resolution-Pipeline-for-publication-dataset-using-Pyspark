{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1706386110185,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yG4NFSSoiE2c","outputId":"e59def24-9b68-43c2-edfc-21ae0a270b0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["java-1.11.0-openjdk-amd64  java-11-openjdk-amd64\n"]}],"source":["!ls /usr/lib/jvm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjVQZm7rijIQ"},"outputs":[],"source":["# !apt-get update\n","# !apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etzsx0Fzj_Cr"},"outputs":[],"source":["# !wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n","#  # Unzip file\n","# !tar -xvzf spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72445,"status":"ok","timestamp":1706612609055,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"clqxjHynkcmU","outputId":"165da82c-bb3b-4315-8418-ea75f7e17af2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=ea55568a35ff6aa884f8e4f0a1997fb868763a7b45d4e8c41c03f36157bc473a\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n"]}],"source":["!pip install -q findspark\n","!pip install pyspark"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18322,"status":"ok","timestamp":1706612627358,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"F3-bQEZ3QZXs","outputId":"0812df39-40d1-4122-a9ec-797e87316a0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-levenshtein\n","  Downloading python_Levenshtein-0.23.0-py3-none-any.whl (9.4 kB)\n","Collecting Levenshtein==0.23.0 (from python-levenshtein)\n","  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.23.0->python-levenshtein)\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-levenshtein\n","Successfully installed Levenshtein-0.23.0 python-levenshtein-0.23.0 rapidfuzz-3.6.1\n"]}],"source":["!pip install python-levenshtein"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bFlvnLhk-8K"},"outputs":[],"source":["#import findspark\n","#findspark.init()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yslhrL1ajiWv","executionInfo":{"status":"ok","timestamp":1706612628142,"user_tz":-60,"elapsed":796,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["from pyspark.sql.session import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n","from pyspark.sql.functions import split\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql.functions import col, concat_ws\n","from pyspark.sql.functions import regexp_replace, regexp_extract, collect_list, explode, udf\n","from pyspark.sql.types import DoubleType\n","from Levenshtein import distance, ratio"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23512,"status":"ok","timestamp":1706612651646,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"8p-VjPhzy8WY","outputId":"cfd5162c-f302-4ac2-8bee-a110c8728712"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1706386139559,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yP2gSg3Cc6Xi","outputId":"ee01354c-962e-480d-94a1-7cc8789d5c32"},"outputs":[{"output_type":"stream","name":"stdout","text":["acm_1995_2004.csv\t\t     dblp_1995_2004.csv     dia_assignments_v2.ipynb\n","acm_1995_2004_specialCharsTitle.csv  dblp.txt\n","acm.txt\t\t\t\t     dia_assignments.ipynb\n"]}],"source":["!ls /content/gdrive/MyDrive/'Colab Notebooks'/Dia_Exercise/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1706386139783,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"LUk0qWOY_zoM","outputId":"fe223cba-8991-43ea-e4b1-30990d54ce39"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TestMamun.txt\n"]}],"source":["!ls /content/gdrive/MyDrive/TestMamun.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBVofdjCdoPM"},"outputs":[],"source":["file_path_dblp = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/dblp.txt\"\n","file_path_acm = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/acm.txt\""]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SED3QOxKUX2-","executionInfo":{"status":"ok","timestamp":1706612651646,"user_tz":-60,"elapsed":18,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["file_path = \"/content/gdrive/MyDrive/TestMamun_2.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OvCGTUOfTpsV"},"outputs":[],"source":["file_path = file_path_dblp"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SLHnRBgst2tv","executionInfo":{"status":"ok","timestamp":1706612669767,"user_tz":-60,"elapsed":18135,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["spark = SparkSession.builder.appName(\"RDDPrintExample\").getOrCreate()\n","\n","# Define the custom delimiter\n","delimiter = \"\\n\\n\"\n","\n","# Create an RDD using newAPIHadoopFile with TextInputFormat\n","rdd = spark.sparkContext.newAPIHadoopFile(\n","    file_path,\n","    \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n","    \"org.apache.hadoop.io.LongWritable\",\n","    \"org.apache.hadoop.io.Text\",\n","    conf={\"textinputformat.record.delimiter\": delimiter},\n",")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"NBl0vHoOzHsj","executionInfo":{"status":"ok","timestamp":1706612669769,"user_tz":-60,"elapsed":20,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["# Define the schema\n","pub_schema = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"authors\", StringType(), True),\n","    StructField(\"year\", StringType(), True),\n","    StructField(\"journal\", StringType(), True),\n","    StructField(\"index\", StringType(), True),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyReVzwj2KcD"},"outputs":[],"source":["data = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    (\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#*')), None),  # Paper Title\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#@')), None),  # Authors\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#t')), None),  # Year\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#c')), None),  # Publication Venue\n","        next((field[6:] for field in x[1].splitlines() if field.startswith('#index')), None)  # Index ID\n","    )\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3520,"status":"ok","timestamp":1706386162795,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"7RybdowF2N_R","outputId":"e9bcd044-7c6b-4ea3-9ad6-35e16b389843"},"outputs":[{"output_type":"stream","name":"stdout","text":["('INFORMS Journal on Computing', None, '2014', 'INFORMS Journal on Computing', '558ac6e0612c41e6b9d39eed')\n","('Pushout-complements and basic concepts of grammars in toposes', 'Yasuo Kawahara', '1990', 'Theoretical Computer Science', '5390879920f70186a0d422b8')\n","('Effective constructors the formal series of trees (French)', 'Symeon Bozapalidis', '1990', 'Theoretical Computer Science', '5390879920f70186a0d422b6')\n","('The DataPaper: living in the virtual world', 'Mark Green, Chris Shaw', '1990', 'Graphics Interface 1990', '555aa9a345ce207198fe0ae8')\n","('Using program slicing in software maintenance', 'Keith Brian Gallagher', '1990', 'Using program slicing in software maintenance', '5390879920f70186a0d422ab')\n"]}],"source":["for el in data.take(5):\n","    print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14958,"status":"ok","timestamp":1706386177746,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"4C6Cpt8dAQCr","outputId":"26151fbd-69ca-4711-c927-4b0ba58ecdc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------------------------------+-------------------------------+----+----------------------------------------------------------------------------------------------------------------------------+------------------------+\n","|title                                                                                                                       |authors                        |year|journal                                                                                                                     |index                   |\n","+----------------------------------------------------------------------------------------------------------------------------+-------------------------------+----+----------------------------------------------------------------------------------------------------------------------------+------------------------+\n","|INFORMS Journal on Computing                                                                                                |NULL                           |2014|INFORMS Journal on Computing                                                                                                |558ac6e0612c41e6b9d39eed|\n","|Pushout-complements and basic concepts of grammars in toposes                                                               |Yasuo Kawahara                 |1990|Theoretical Computer Science                                                                                                |5390879920f70186a0d422b8|\n","|Effective constructors the formal series of trees (French)                                                                  |Symeon Bozapalidis             |1990|Theoretical Computer Science                                                                                                |5390879920f70186a0d422b6|\n","|The DataPaper: living in the virtual world                                                                                  |Mark Green, Chris Shaw         |1990|Graphics Interface 1990                                                                                                     |555aa9a345ce207198fe0ae8|\n","|Using program slicing in software maintenance                                                                               |Keith Brian Gallagher          |1990|Using program slicing in software maintenance                                                                               |5390879920f70186a0d422ab|\n","|Optimistic processing for distributed database systems in a partitioned network                                             |Ann Tracy Goodman              |1990|Optimistic processing for distributed database systems in a partitioned network                                             |5390879920f70186a0d422ca|\n","|Probabilistic analysis of geometric algorithms                                                                              |Mordecai J. Golin              |1990|Probabilistic analysis of geometric algorithms                                                                              |5390879920f70186a0d422d1|\n","|Active bias adjustment for incremental, supervised concept learning                                                         |Diana Faye Gordon              |1990|Active bias adjustment for incremental, supervised concept learning                                                         |5390879920f70186a0d422d3|\n","|Integration, the VLSI Journal                                                                                               |L. Spaanenburg                 |1984|Integration, the VLSI Journal                                                                                               |558e21a40cf222bc17bc0dd2|\n","|Complete problems, creative sets and isomorphism conjectures                                                                |Krishnamurthy Ganesan          |1990|Complete problems, creative sets and isomorphism conjectures                                                                |5390879920f70186a0d422a9|\n","|Predicting the present with search engine data                                                                              |Hal Varian                     |2013|Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining                          |552bd3d045cec781e877d463|\n","|A feature dictionary to support database translation, information retrieval, intelligent medical records, and expert systems|Frank F. Naeymi-Rad            |1990|A feature dictionary to support database translation, information retrieval, intelligent medical records, and expert systems|5390879920f70186a0d422cd|\n","|Service specification and protocol construction for a layered architecture                                                  |Sandra Lynn Murphy             |1990|Service specification and protocol construction for a layered architecture                                                  |5390879920f70186a0d422c4|\n","|Criteria for evaluation and construction of C(2) interpolation methods                                                      |Tylene Stratton Garrett        |1990|Criteria for evaluation and construction of C(2) interpolation methods                                                      |5390879920f70186a0d422bd|\n","|Ada/ANNA specification analysis                                                                                             |Randall B. Neff                |1990|Ada/ANNA specification analysis                                                                                             |5390879920f70186a0d422d0|\n","|Transformations of sequential specifications into concurrent specifications by synchronization guards                       |Ryszard Janicki, Tomasz Müldner|1989|Conference proceedings on Algebraic methodology and software technology                                                     |5390879920f70186a0d422b1|\n","|Infosystems                                                                                                                 |Jr.,W L Rhodes                 |1986|Infosystems                                                                                                                 |558fed840cf2e9668dc4cec8|\n","|MIDAS: musical instrument digitizer and synthesizer                                                                         |James Clifford Gower           |1990|MIDAS: musical instrument digitizer and synthesizer                                                                         |5390879920f70186a0d422d8|\n","|Ada style tasking model: concurrent language design for adaptive scheduling                                                 |Daniel E. Nohl                 |1990|Ada style tasking model: concurrent language design for adaptive scheduling                                                 |5390879920f70186a0d422da|\n","|Positive relativizations for log space computability                                                                        |Seinosuke Toda                 |1990|Theoretical Computer Science                                                                                                |5390879920f70186a0d422b5|\n","+----------------------------------------------------------------------------------------------------------------------------+-------------------------------+----+----------------------------------------------------------------------------------------------------------------------------+------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# # Apply the schema to the RDD 'a'\n","df = spark.createDataFrame(data, schema=pub_schema)\n","df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4605,"status":"ok","timestamp":1706386730879,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"8b8nylLp2TF-","outputId":"814a2d87-b41c-4024-e05d-7adceb2cedd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------+------------------------------------------------------------+----+------------------------------------------+------------------------+\n","|title                                                                           |authors                                                     |year|journal                                   |index                   |\n","+--------------------------------------------------------------------------------+------------------------------------------------------------+----+------------------------------------------+------------------------+\n","|Protein Kinase C, Models of.                                                    |Kim L. Blackwell                                            |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e8|\n","|Stimulus Reconstruction from Cortical Responses.                                |Nima Mesgarani                                              |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e9|\n","|Neuromuscular Control Systems, Models of.                                       |James J. Abbas                                              |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273ea|\n","|Spinal Interfaces: Overview.                                                    |Michel Lemay                                                |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273eb|\n","|Visual Prosthesis, Subretinal Devices.                                          |Eberhart Zrenner                                            |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273ec|\n","|Comparative Analysis of Half-Center Central Pattern Generators (CPGs).          |Jonathan Rubin                                              |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e0|\n","|Basal Ganglia: Decision-Making.                                                 |Wei Wei, Xiao-Jing Wang                                     |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e1|\n","|Generalized Linear Models for Point Process Analyses of Neural Spiking Activity.|Zhe Chen, Emery N. Brown                                    |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e2|\n","|Q10: The Effect of Temperature on Ion Channel Kinetics.                         |David C. Sterratt                                           |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e3|\n","|Pitch Perception, Models.                                                       |Jan W. H. Schnupp                                           |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e4|\n","|Vertebrate Pattern Generation: Overview.                                        |Ilya Rybak                                                  |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e5|\n","|Spatiotemporal Energy Models.                                                   |Wyeth Bair                                                  |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e6|\n","|Connectivity Analysis in Normal and Pathological Brains.                        |Claus C. Hilgetag                                           |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273e7|\n","|On Solving Efficiently the View Selection Problem under Bag-semantics.          |Foto N. Afrati, Matthew Damigos, Manolis Gergatsoulis       |2008|BIRTE (Informal Proceedings)              |53e9b29cb7602d9703d46c7d|\n","|Spinal Stimulation for Parkinson Treatment.                                     |Romulo Fuentes                                              |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273cf|\n","|Accumulation of Evidence in Decision Making.                                    |Alexander C. Huk, Leor N. Katz, Jacob L. Yates              |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273d8|\n","|Coordinate Transformations, Role of Spinal Cord in.                             |Yifat Prut                                                  |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273d9|\n","|Pathological Changes in Peripheral Nerve Excitability.                          |Steven A. Prescott                                          |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273da|\n","|Spike Train Analysis: Overview.                                                 |Sonja Grün                                                  |2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273db|\n","|Phase Transitions, Neural Population Models and.                                |D. Alistair Steyn-Ross, Moira L. Steyn-Ross, Jamie W. Sleigh|2014|Encyclopedia of Computational Neuroscience|55503da645ce0a409eb273dc|\n","+--------------------------------------------------------------------------------+------------------------------------------------------------+----+------------------------------------------+------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["def create_dataframe_from_file(file_path, pub_schema):\n","    # Define the custom delimiter\n","    delimiter = \"\\n\\n\"\n","\n","    # Create an RDD using newAPIHadoopFile with TextInputFormat\n","    rdd = spark.sparkContext.newAPIHadoopFile(\n","        file_path,\n","        \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n","        \"org.apache.hadoop.io.LongWritable\",\n","        \"org.apache.hadoop.io.Text\",\n","        conf={\"textinputformat.record.delimiter\": delimiter},\n","    )\n","\n","    # Filter and map the RDD to extract relevant fields\n","    data_rdd = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","        (\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#*')), None),  # Paper Title\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#@')), None),  # Authors\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#t')), None),  # Year\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#c')), None),  # Publication Venue\n","            next((field[6:] for field in x[1].splitlines() if field.startswith('#index')), None)  # Index ID\n","        )\n","    ))\n","\n","    # Create DataFrame using the defined schema\n","    df = spark.createDataFrame(data_rdd, schema=pub_schema)\n","\n","    return df\n","\n","df = create_dataframe_from_file(file_path, pub_schema)\n","df.show(truncate=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TL2at22F3G3r"},"outputs":[],"source":["def filter_and_clean_df(df):\n","    # Filter publications between 1995 and 2004 in VLDB and SIGMOD venues\n","    filtered_df = df.filter(\n","        (col(\"year\").cast(\"int\").between(1995, 2004)) &\n","        (col(\"journal\").rlike(\"(?i)SIGMOD|VLDB\"))\n","    )\n","\n","    # Clean the journal column\n","    cleaned_df = filtered_df.withColumn(\"journal\",\n","                                        regexp_replace(\n","                                            regexp_replace(\"journal\", \"(?i).*\\\\bVLDB\\\\b.*\", \"VLDB\"),\n","                                            \"(?i).*\\\\bSIGMOD\\\\b.*\", \"SIGMOD\"))\n","\n","    return cleaned_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RTvEUUva3pGV"},"outputs":[],"source":["def remove_special_chars(df):\n","  pattern = r'[^\\w,\\s]'\n","  return df.withColumn(\"title\", regexp_replace(\"title\", pattern,'')).withColumn(\"authors\", regexp_replace(\"authors\", pattern,''))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"xxSITF3Q4FtD","executionInfo":{"status":"ok","timestamp":1706612669769,"user_tz":-60,"elapsed":16,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def write_to_csv(df, path):\n","  df.repartition(1).write.format('csv').option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").save(path, mode='overwrite')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"GynP3kBs4vvR","executionInfo":{"status":"ok","timestamp":1706612670986,"user_tz":-60,"elapsed":1230,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def levenshtein_ratio(s1, s2):\n","    return ratio(s1, s2)\n","\n","# Register the UDF to calculate Levenshtein ratio\n","levenshtein_ratio_udf = udf(levenshtein_ratio, DoubleType())\n","\n","def find_duplicates_for_ground_truth(df1, df2, threshold=0.5):\n","    # Select only the \"title\" and \"authors\" columns from df1 and alias them\n","    df1_subset = df1.select(col(\"title\").alias(\"title_1\"), col(\"authors\").alias(\"authors_1\"))\n","\n","    # Select only the \"title\" and \"authors\" columns from df2 and alias them\n","    df2_subset = df2.select(col(\"title\").alias(\"title_2\"), col(\"authors\").alias(\"authors_2\"))\n","\n","    # Join the subsets of df1 and df2 containing \"title\" and \"authors\" columns\n","    joined_df = df1_subset.crossJoin(df2_subset)\n","\n","    # Calculate the similarity score using Levenshtein ratio on \"title\" and \"authors\"\n","    similarity_df = joined_df.withColumn(\"Title_Similarity\", levenshtein_ratio_udf(joined_df[\"title_1\"], joined_df[\"title_2\"])) \\\n","                             .withColumn(\"Authors_Similarity\", levenshtein_ratio_udf(joined_df[\"authors_1\"], joined_df[\"authors_2\"]))\n","\n","    # Filter the DataFrame to keep only the pairs with similarity scores greater than or equal to the specified threshold\n","    duplicates_df = similarity_df.filter((similarity_df[\"Title_Similarity\"] >= threshold) & (similarity_df[\"Authors_Similarity\"] >= threshold))\n","\n","    # Select and rename the relevant columns\n","    duplicates_df = duplicates_df.select(duplicates_df[\"title_1\"].alias(\"Title1\"),\n","                                         duplicates_df[\"title_2\"].alias(\"Title2\"),\n","                                         duplicates_df[\"authors_1\"].alias(\"Authors1\"),\n","                                         duplicates_df[\"authors_2\"].alias(\"Authors2\"),\n","                                         duplicates_df[\"Title_Similarity\"],\n","                                         duplicates_df[\"Authors_Similarity\"])\n","\n","    return duplicates_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnuFP0kc4vSI"},"outputs":[],"source":["df_dblp = create_dataframe_from_file(file_path_dblp, pub_schema)\n","#df_acm = create_dataframe_from_file(file_path_acm, pub_schema)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiFPien35UC9"},"outputs":[],"source":["df_dblp_clean = remove_special_chars(filter_and_clean_df(df_dblp))\n","#df_acm_clean = remove_special_chars(filter_and_clean_df(df_acm))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15293,"status":"ok","timestamp":1706386952260,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yra9bAaz5T_u","outputId":"42b9fcd5-3897-43a9-99cb-a8d700368a4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+----+-------+--------------------+\n","|               title|             authors|year|journal|               index|\n","+--------------------+--------------------+----+-------+--------------------+\n","|An initial study ...|      Amol Deshpande|2004| SIGMOD|53e9a515b7602d970...|\n","|Engineering Feder...|Stefan Conrad, Wi...|1999| SIGMOD|53e9b275b7602d970...|\n","|Information Findi...|Tak W Yan, Hector...|1995| SIGMOD|53e9a5beb7602d970...|\n","|       Editors Notes|      Jennifer Widom|1995| SIGMOD|53e99800b7602d970...|\n","|Report on the 5th...|HansJoachim Lenz,...|2003| SIGMOD|53e9a718b7602d970...|\n","|       Editors Notes|            Ling Liu|2002| SIGMOD|53e99800b7602d970...|\n","|Report from the N...|Amit P Sheth, Dim...|1996| SIGMOD|53e99e6ab7602d970...|\n","|TODS Perceptions ...| Richard T Snodgrass|2002| SIGMOD|53e99ae6b7602d970...|\n","|SQLMED  A Status ...|Jim Melton, JanEi...|2002| SIGMOD|53e9b4d4b7602d970...|\n","|2003 SIGMOD Innov...| Donald D Chamberlin|2003| SIGMOD|53e9b4a5b7602d970...|\n","|Jeffrey D Ullman ...|   Marianne Winslett|2001| SIGMOD|53e9aadfb7602d970...|\n","|Research issues f...|Leslie D Fife, Le...|2003| SIGMOD|53e9a7b3b7602d970...|\n","|      Chairs Message| Richard T Snodgrass|1998| SIGMOD|53e99809b7602d970...|\n","|An approach to co...|Debajyoti Mukhopa...|2003| SIGMOD|53e9a515b7602d970...|\n","|A Comparison of T...|Carl Medsker, Mar...|1995| SIGMOD|53e9bd1eb7602d970...|\n","|Object Query Stan...|       Andrew E Wade|1996| SIGMOD|53e9983db7602d970...|\n","|Constraints for S...|Peter Buneman, We...|2001| SIGMOD|53e9b991b7602d970...|\n","|Database Principl...|       Leonid Libkin|1999| SIGMOD|53e99a26b7602d970...|\n","|Report on DART 96...|Krithi Ramamritha...|1997| SIGMOD|53e9a743b7602d970...|\n","|A MultiAgent Syst...|Riza Cenk Erdur, ...|2002| SIGMOD|53e9bd8cb7602d970...|\n","+--------------------+--------------------+----+-------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["df_dblp_clean.show()"]},{"cell_type":"code","source":["path_dblp_csv = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/dblp_1995_2004.csv\"\n","#write_to_csv(df_dblp_clean, path_dblp_csv)"],"metadata":{"id":"fz8XXaUehFZY","executionInfo":{"status":"ok","timestamp":1706612670987,"user_tz":-60,"elapsed":13,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1212,"status":"ok","timestamp":1706381913451,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"U9CsuXgBPpPN","outputId":"9f7b56d1-46b6-4af4-becc-d6413f7648f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+----+-------+--------------------+\n","|               title|             authors|year|journal|               index|\n","+--------------------+--------------------+----+-------+--------------------+\n","|The next database...|            Jim Gray|2004| SIGMOD|5390972920f70186a...|\n","|The role of crypt...|         Ueli Maurer|2004| SIGMOD|5390972920f70186a...|\n","|Tree logical clas...|Stelios Paparizos...|2004| SIGMOD|5390972920f70186a...|\n","|Adaptive stream r...|Ankur Jain, Edwar...|2004| SIGMOD|5390972920f70186a...|\n","|Holistic UDAFs at...|Graham Cormode, T...|2004| SIGMOD|5390972920f70186a...|\n","|Online eventdrive...|Huanmei Wu, Betty...|2004| SIGMOD|5390972920f70186a...|\n","|Using the structu...|Kristina Lerman, ...|2004| SIGMOD|5390972920f70186a...|\n","|FleXPath flexible...|Sihem AmerYahia, ...|2004| SIGMOD|5390972920f70186a...|\n","|An interactive cl...|Wensheng Wu, Clem...|2004| SIGMOD|5390972920f70186a...|\n","|Lazy query evalua...|Serge Abiteboul, ...|2004| SIGMOD|5390972920f70186a...|\n","|Colorful XML one ...|H V Jagadish, Lak...|2004| SIGMOD|5390972920f70186a...|\n","|Effective use of ...|Surajit Chaudhuri...|2004| SIGMOD|5390972920f70186a...|\n","|The Priority Rtre...|Lars Arge, Mark d...|2004| SIGMOD|5390972920f70186a...|\n","|Online maintenanc...|Christopher Jerma...|2004| SIGMOD|5390972920f70186a...|\n","|Integrating verti...|Sanjay Agrawal, V...|2004| SIGMOD|5390972920f70186a...|\n","|Graph indexing a ...|Xifeng Yan, Phili...|2004| SIGMOD|5390972920f70186a...|\n","|Conditional selec...|Nicolas Bruno, Su...|2004| SIGMOD|5390972920f70186a...|\n","|Computing Cluster...|Christian Bhm, Ka...|2004| SIGMOD|5390972920f70186a...|\n","|Transaction suppo...|Goetz Graefe, Mic...|2004| SIGMOD|5390972920f70186a...|\n","|Fast computation ...|Naga K Govindaraj...|2004| SIGMOD|5390972920f70186a...|\n","+--------------------+--------------------+----+-------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["df_acm_clean.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6bqKHj0P3k3"},"outputs":[],"source":["duplicates_find_naive = find_duplicates_for_ground_truth(df_acm_clean, df_dblp_clean)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"cJkKkxL3QxBr","executionInfo":{"status":"ok","timestamp":1706612670988,"user_tz":-60,"elapsed":10,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["csv_path_duplicates = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/duplicates_dblp.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-nMfLl7P3iE"},"outputs":[],"source":["write_to_csv(duplicates_find_naive, csv_path_duplicates)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UDGYwtVP3ZA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"id":"zZHS5lkGP3WJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706612933037,"user_tz":-60,"elapsed":984,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"ad57f618-727e-430b-fde6-b18857920ae0"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+----+-------+--------------------+\n","|               title|             authors|year|journal|               index|\n","+--------------------+--------------------+----+-------+--------------------+\n","|An initial study ...|      Amol Deshpande|2004| SIGMOD|53e9a515b7602d970...|\n","|Engineering Feder...|Stefan Conrad, Wi...|1999| SIGMOD|53e9b275b7602d970...|\n","|Information Findi...|Tak W Yan, Hector...|1995| SIGMOD|53e9a5beb7602d970...|\n","|       Editors Notes|      Jennifer Widom|1995| SIGMOD|53e99800b7602d970...|\n","|Report on the 5th...|HansJoachim Lenz,...|2003| SIGMOD|53e9a718b7602d970...|\n","|       Editors Notes|            Ling Liu|2002| SIGMOD|53e99800b7602d970...|\n","|Report from the N...|Amit P Sheth, Dim...|1996| SIGMOD|53e99e6ab7602d970...|\n","|TODS Perceptions ...| Richard T Snodgrass|2002| SIGMOD|53e99ae6b7602d970...|\n","|SQLMED  A Status ...|Jim Melton, JanEi...|2002| SIGMOD|53e9b4d4b7602d970...|\n","|2003 SIGMOD Innov...| Donald D Chamberlin|2003| SIGMOD|53e9b4a5b7602d970...|\n","|Jeffrey D Ullman ...|   Marianne Winslett|2001| SIGMOD|53e9aadfb7602d970...|\n","|Research issues f...|Leslie D Fife, Le...|2003| SIGMOD|53e9a7b3b7602d970...|\n","|      Chairs Message| Richard T Snodgrass|1998| SIGMOD|53e99809b7602d970...|\n","|An approach to co...|Debajyoti Mukhopa...|2003| SIGMOD|53e9a515b7602d970...|\n","|A Comparison of T...|Carl Medsker, Mar...|1995| SIGMOD|53e9bd1eb7602d970...|\n","|Object Query Stan...|       Andrew E Wade|1996| SIGMOD|53e9983db7602d970...|\n","|Constraints for S...|Peter Buneman, We...|2001| SIGMOD|53e9b991b7602d970...|\n","|Database Principl...|       Leonid Libkin|1999| SIGMOD|53e99a26b7602d970...|\n","|Report on DART 96...|Krithi Ramamritha...|1997| SIGMOD|53e9a743b7602d970...|\n","|A MultiAgent Syst...|Riza Cenk Erdur, ...|2002| SIGMOD|53e9bd8cb7602d970...|\n","+--------------------+--------------------+----+-------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["def read_csv_with_schema(spark, file_path, schema):\n","    \"\"\"\n","    Read records from a CSV file using a specified schema.\n","\n","    Args:\n","    - spark: SparkSession object\n","    - file_path: path to the CSV file\n","    - schema: schema to be applied to the DataFrame\n","\n","    Returns:\n","    - DataFrame containing the records from the CSV file with the specified schema\n","    \"\"\"\n","    # Read CSV file with schema\n","    df = spark.read.csv(file_path, schema=schema, header=True)\n","\n","    return df\n","\n","# file_path_acm = \"/kaggle/input/pubdata/acm_1995_2004.csv\"\n","# file_path_dblp = \"/kaggle/input/pubdata/dblp_1995_2004.csv\"\n","\n","# Read CSV file with schema\n","df_acm = read_csv_with_schema(spark, path_dblp_csv, pub_schema)\n","#df_dblp = read_csv_with_schema(spark, file_path_dblp, pub_schema)\n","\n","# Show the DataFrame\n","df_acm.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2256,"status":"ok","timestamp":1706366263928,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"y2bgAFPPHOTz","outputId":"8eb0e7a0-ee9a-47ce-90ba-a2326b18325d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+----+--------------------+--------------------+\n","|               title|             authors|year|             journal|               index|\n","+--------------------+--------------------+----+--------------------+--------------------+\n","|The next database...|            Jim Gray|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|The role of crypt...|         Ueli Maurer|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Tree logical clas...|Stelios Paparizos...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Adaptive stream r...|Ankur Jain, Edwar...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Holistic UDAFs at...|Graham Cormode, T...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Online event-driv...|Huanmei Wu, Betty...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Using the structu...|Kristina Lerman, ...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|FleXPath: flexibl...|Sihem Amer-Yahia,...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|An interactive cl...|Wensheng Wu, Clem...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Lazy query evalua...|Serge Abiteboul, ...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Colorful XML: one...|H. V. Jagadish, L...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Effective use of ...|Surajit Chaudhuri...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|The Priority R-tr...|Lars Arge, Mark d...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Online maintenanc...|Christopher Jerma...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Integrating verti...|Sanjay Agrawal, V...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Graph indexing: a...|Xifeng Yan, Phili...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Conditional selec...|Nicolas Bruno, Su...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Computing Cluster...|Christian Böhm, K...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Transaction suppo...|Goetz Graefe, Mic...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","|Fast computation ...|Naga K. Govindara...|2004|SIGMOD '04 Procee...|5390972920f70186a...|\n","+--------------------+--------------------+----+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Filter publications between 1995 and 2004 in VLDB and SIGMOD venues\n","filtered_df = df.filter(\n","    (col(\"year\").cast(\"int\").between(1995, 2004)) &\n","    (col(\"journal\").rlike(\"(?i)SIGMOD|VLDB\"))\n",")\n","filtered_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1979,"status":"ok","timestamp":1706366265899,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"-hSp2LsTauz9","outputId":"94d65ca9-957e-4c6f-d695-e9b10e47027f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","|title                                                                                          |authors                                                                                            |year|journal|index                   |\n","+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","|The next database revolution                                                                   |Jim Gray                                                                                           |2004|SIGMOD |5390972920f70186a0dfac85|\n","|The role of cryptography in database security                                                  |Ueli Maurer                                                                                        |2004|SIGMOD |5390972920f70186a0dfac86|\n","|Tree logical classes for efficient evaluation of XQuery                                        |Stelios Paparizos, Yuqing Wu, Laks V. S. Lakshmanan, H. V. Jagadish                                |2004|SIGMOD |5390972920f70186a0dfac8d|\n","|Adaptive stream resource management using Kalman Filters                                       |Ankur Jain, Edward Y. Chang, Yuan-Fang Wang                                                        |2004|SIGMOD |5390972920f70186a0dfac88|\n","|Holistic UDAFs at streaming speeds                                                             |Graham Cormode, Theodore Johnson, Flip Korn, S. Muthukrishnan, Oliver Spatscheck, Divesh Srivastava|2004|SIGMOD |5390972920f70186a0dfac8a|\n","|Online event-driven subsequence matching over financial data streams                           |Huanmei Wu, Betty Salzberg, Donghui Zhang                                                          |2004|SIGMOD |5390972920f70186a0dfac89|\n","|Using the structure of Web sites for automatic segmentation of tables                          |Kristina Lerman, Lise Getoor, Steven Minton, Craig Knoblock                                        |2004|SIGMOD |5390972920f70186a0dfac91|\n","|FleXPath: flexible structure and full-text querying for XML                                    |Sihem Amer-Yahia, Laks V. S. Lakshmanan, Shashank Pandit                                           |2004|SIGMOD |5390972920f70186a0dfac8e|\n","|An interactive clustering-based approach to integrating source query interfaces on the deep Web|Wensheng Wu, Clement Yu, AnHai Doan, Weiyi Meng                                                    |2004|SIGMOD |5390972920f70186a0dfac8f|\n","|Lazy query evaluation for Active XML                                                           |Serge Abiteboul, Omar Benjelloun, Bogdan Cautis, Ioana Manolescu, Tova Milo, Nicoleta Preda        |2004|SIGMOD |5390972920f70186a0dfac9a|\n","|Colorful XML: one hierarchy isn't enough                                                       |H. V. Jagadish, Laks V. S. Lakshmanan, Monica Scannapieco, Divesh Srivastava, Nuwee Wiwatwattana   |2004|SIGMOD |5390972920f70186a0dfac9c|\n","|Effective use of block-level sampling in statistics estimation                                 |Surajit Chaudhuri, Gautam Das, Utkarsh Srivastava                                                  |2004|SIGMOD |5390972920f70186a0dfac9f|\n","|The Priority R-tree: a practically efficient and worst-case optimal R-tree                     |Lars Arge, Mark de Berg, Herman J. Haverkort, Ke Yi                                                |2004|SIGMOD |5390972920f70186a0dfaca4|\n","|Online maintenance of very large random samples                                                |Christopher Jermaine, Abhijit Pol, Subramanian Arumugam                                            |2004|SIGMOD |5390972920f70186a0dfaca0|\n","|Integrating vertical and horizontal partitioning into automated physical database design       |Sanjay Agrawal, Vivek Narasayya, Beverly Yang                                                      |2004|SIGMOD |5390972920f70186a0dfaca5|\n","|Graph indexing: a frequent structure-based approach                                            |Xifeng Yan, Philip S. Yu, Jiawei Han                                                               |2004|SIGMOD |5390972920f70186a0dfaca3|\n","|Conditional selectivity for statistics on query expressions                                    |Nicolas Bruno, Surajit Chaudhuri                                                                   |2004|SIGMOD |5390972920f70186a0dfaca1|\n","|Computing Clusters of Correlation Connected objects                                            |Christian Böhm, Karin Kailing, Peer Kröger, Arthur Zimek                                           |2004|SIGMOD |5390972920f70186a0dfacad|\n","|Transaction support for indexed summary views                                                  |Goetz Graefe, Michael Zwilling                                                                     |2004|SIGMOD |5390972920f70186a0dfaca2|\n","|Fast computation of database operations using graphics processors                              |Naga K. Govindaraju, Brandon Lloyd, Wei Wang, Ming Lin, Dinesh Manocha                             |2004|SIGMOD |5390972920f70186a0dfac99|\n","+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["# Clean the journal column\n","# Clean the journal column in a single line\n","cleaned_df = filtered_df.withColumn(\"journal\",\n","                                    regexp_replace(\n","                                        regexp_replace(\"journal\", \"(?i).*\\\\bVLDB\\\\b.*\", \"VLDB\"),\n","                                        \"(?i).*\\\\bSIGMOD\\\\b.*\", \"SIGMOD\"))\n","# Show the cleaned DataFrame\n","cleaned_df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139765,"status":"ok","timestamp":1706366405656,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"ibK167ipooRe","outputId":"a29914d4-baa0-414d-b9e8-fbef9f7c7d17"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+\n","|index|\n","+-----+\n","+-----+\n","\n"]}],"source":["# Identify duplicates based on the 'index' column\n","# duplicate_entries = cleaned_df.groupBy(\"index\").count().where(col(\"count\") > 1)\n","# duplicate_indices = duplicate_entries.select(\"index\")\n","# duplicate_indices.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCZgoG2Ls0nD"},"outputs":[],"source":["# #drop them if any\n","# # df_no_duplicates = cleaned_df.dropDuplicates(subset=[\"index\"])\n","# # df_no_duplicates.show()\n","# special_characters_df = cleaned_df.select(\"title\").distinct().select(regexp_extract(col(\"title\"), r'[^a-zA-Z0-9\\s]', 0).alias(\"special_characters\"))\n","\n","# # Show the special characters\n","# special_characters_df.show(truncate=False)"]},{"cell_type":"code","source":["def remove_null_rows(dataframe):\n","    return dataframe.dropna()"],"metadata":{"id":"bMN9NZJZD0YB","executionInfo":{"status":"ok","timestamp":1706612980854,"user_tz":-60,"elapsed":338,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"pcZD-6pGtN29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706613013741,"user_tz":-60,"elapsed":1472,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"d0700655-15f9-4ef9-d7d8-3436a1a42f23"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------+------------------+----+-------+------------------------+-----+\n","|title         |authors           |year|journal|index                   |count|\n","+--------------+------------------+----+-------+------------------------+-----+\n","|Editors Notes |Ling Liu          |2002|SIGMOD |53e99800b7602d970200b603|4    |\n","|Editors Notes |Ling Liu          |2002|SIGMOD |53e99800b7602d970200b603|4    |\n","|Editors Notes |Ling Liu          |2002|SIGMOD |53e99800b7602d970200b603|4    |\n","|Editors Notes |Ling Liu          |2002|SIGMOD |53e99800b7602d970200b603|4    |\n","|Chairs Message|M Tamer zsu       |2002|SIGMOD |53e99809b7602d970201f8e7|3    |\n","|Chairs Message|M Tamer zsu       |2002|SIGMOD |53e99809b7602d970201f8e7|3    |\n","|Chairs Message|M Tamer zsu       |2002|SIGMOD |53e99809b7602d970201f8e7|3    |\n","|Editors Notes |Ling Liu          |2004|SIGMOD |53e99800b7602d970200b601|3    |\n","|Editors Notes |Ling Liu          |2004|SIGMOD |53e99800b7602d970200b601|3    |\n","|Chairs Message|M Tamer zsu       |2004|SIGMOD |53e99809b7602d970201f928|3    |\n","|Editors Notes |Michael J Franklin|1997|SIGMOD |53e99800b7602d970200b5fd|3    |\n","|Chairs Message|M Tamer zsu       |2004|SIGMOD |53e99809b7602d970201f928|3    |\n","|Editors Notes |Michael J Franklin|1997|SIGMOD |53e99800b7602d970200b5fd|3    |\n","|Editors Notes |Jennifer Widom    |1996|SIGMOD |53e99800b7602d970200b61b|3    |\n","|Editors Notes |Michael J Franklin|1997|SIGMOD |53e99800b7602d970200b5fd|3    |\n","|Editors Notes |Michael J Franklin|2000|SIGMOD |53e99800b7602d970200b603|3    |\n","|Editors Notes |Michael J Franklin|1998|SIGMOD |53e99800b7602d970200b5fd|3    |\n","|Editors Notes |Ling Liu          |2003|SIGMOD |53e99800b7602d970200b604|3    |\n","|Editors Notes |Michael J Franklin|1998|SIGMOD |53e99800b7602d970200b5fd|3    |\n","|Editors Notes |Ling Liu          |2004|SIGMOD |53e99800b7602d970200b601|3    |\n","+--------------+------------------+----+-------+------------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, lower, count\n","from pyspark.sql.window import Window\n","\n","def find_duplicates(df):\n","    # Convert titles, authors, and year to lowercase for case-insensitive comparison\n","    df = df.withColumn(\"lower_title\", lower(col(\"title\"))) \\\n","           .withColumn(\"lower_authors\", lower(col(\"authors\")))\n","\n","    # Find duplicates using window function\n","    windowSpec = Window.partitionBy(\"lower_title\", \"lower_authors\", \"year\", \"index\")\n","    df_with_count = df.withColumn(\"count\", count(\"*\").over(windowSpec))\n","\n","    # Filter only rows with count > 1, indicating duplicates\n","    duplicates_df = df_with_count.filter(col(\"count\") > 1).orderBy(col(\"count\").desc()) \\\n","                                 .drop(\"lower_title\", \"lower_authors\")\n","\n","    # Remove duplicates from original DataFrame\n","    df_unique = df_with_count.filter(col(\"count\") == 1).drop(\"count\", \"lower_title\", \"lower_authors\")\n","\n","    return duplicates_df, df_unique\n","\n","df_acm = remove_null_rows(df_acm)\n","duplicates, unique_records = find_duplicates(df_acm)\n","\n","duplicates.show(truncate=False)\n","#unique_records.show()"]},{"cell_type":"code","source":["write_to_csv(duplicates, csv_path_duplicates)"],"metadata":{"id":"dNccpEcfDGBy","executionInfo":{"status":"ok","timestamp":1706613021710,"user_tz":-60,"elapsed":2300,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["write_to_csv(unique_records, \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/unique_dblp.csv\")"],"metadata":{"id":"4GP5s82s_KZb","executionInfo":{"status":"ok","timestamp":1706613023832,"user_tz":-60,"elapsed":1138,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1967,"status":"ok","timestamp":1706366407610,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"gqyvNPlCCdbH","outputId":"75e5f833-857f-4fba-e4d2-71a97a568e7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","|title                                                                                         |authors                                                                                           |year|journal|index                   |\n","+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","|The next database revolution                                                                  |Jim Gray                                                                                          |2004|SIGMOD |5390972920f70186a0dfac85|\n","|The role of cryptography in database security                                                 |Ueli Maurer                                                                                       |2004|SIGMOD |5390972920f70186a0dfac86|\n","|Tree logical classes for efficient evaluation of XQuery                                       |Stelios Paparizos, Yuqing Wu, Laks V S Lakshmanan, H V Jagadish                                   |2004|SIGMOD |5390972920f70186a0dfac8d|\n","|Adaptive stream resource management using Kalman Filters                                      |Ankur Jain, Edward Y Chang, YuanFang Wang                                                         |2004|SIGMOD |5390972920f70186a0dfac88|\n","|Holistic UDAFs at streaming speeds                                                            |Graham Cormode, Theodore Johnson, Flip Korn, S Muthukrishnan, Oliver Spatscheck, Divesh Srivastava|2004|SIGMOD |5390972920f70186a0dfac8a|\n","|Online eventdriven subsequence matching over financial data streams                           |Huanmei Wu, Betty Salzberg, Donghui Zhang                                                         |2004|SIGMOD |5390972920f70186a0dfac89|\n","|Using the structure of Web sites for automatic segmentation of tables                         |Kristina Lerman, Lise Getoor, Steven Minton, Craig Knoblock                                       |2004|SIGMOD |5390972920f70186a0dfac91|\n","|FleXPath flexible structure and fulltext querying for XML                                     |Sihem AmerYahia, Laks V S Lakshmanan, Shashank Pandit                                             |2004|SIGMOD |5390972920f70186a0dfac8e|\n","|An interactive clusteringbased approach to integrating source query interfaces on the deep Web|Wensheng Wu, Clement Yu, AnHai Doan, Weiyi Meng                                                   |2004|SIGMOD |5390972920f70186a0dfac8f|\n","|Lazy query evaluation for Active XML                                                          |Serge Abiteboul, Omar Benjelloun, Bogdan Cautis, Ioana Manolescu, Tova Milo, Nicoleta Preda       |2004|SIGMOD |5390972920f70186a0dfac9a|\n","|Colorful XML one hierarchy isnt enough                                                        |H V Jagadish, Laks V S Lakshmanan, Monica Scannapieco, Divesh Srivastava, Nuwee Wiwatwattana      |2004|SIGMOD |5390972920f70186a0dfac9c|\n","|Effective use of blocklevel sampling in statistics estimation                                 |Surajit Chaudhuri, Gautam Das, Utkarsh Srivastava                                                 |2004|SIGMOD |5390972920f70186a0dfac9f|\n","|The Priority Rtree a practically efficient and worstcase optimal Rtree                        |Lars Arge, Mark de Berg, Herman J Haverkort, Ke Yi                                                |2004|SIGMOD |5390972920f70186a0dfaca4|\n","|Online maintenance of very large random samples                                               |Christopher Jermaine, Abhijit Pol, Subramanian Arumugam                                           |2004|SIGMOD |5390972920f70186a0dfaca0|\n","|Integrating vertical and horizontal partitioning into automated physical database design      |Sanjay Agrawal, Vivek Narasayya, Beverly Yang                                                     |2004|SIGMOD |5390972920f70186a0dfaca5|\n","|Graph indexing a frequent structurebased approach                                             |Xifeng Yan, Philip S Yu, Jiawei Han                                                               |2004|SIGMOD |5390972920f70186a0dfaca3|\n","|Conditional selectivity for statistics on query expressions                                   |Nicolas Bruno, Surajit Chaudhuri                                                                  |2004|SIGMOD |5390972920f70186a0dfaca1|\n","|Computing Clusters of Correlation Connected objects                                           |Christian Bhm, Karin Kailing, Peer Krger, Arthur Zimek                                            |2004|SIGMOD |5390972920f70186a0dfacad|\n","|Transaction support for indexed summary views                                                 |Goetz Graefe, Michael Zwilling                                                                    |2004|SIGMOD |5390972920f70186a0dfaca2|\n","|Fast computation of database operations using graphics processors                             |Naga K Govindaraju, Brandon Lloyd, Wei Wang, Ming Lin, Dinesh Manocha                             |2004|SIGMOD |5390972920f70186a0dfac99|\n","+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------+----+-------+------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["pattern = r'[^\\w,\\s]'\n","cleaned_df = cleaned_df.withColumn(\"title\", regexp_replace(\"title\", pattern,'')).withColumn(\"authors\", regexp_replace(\"authors\", pattern,''))\n","cleaned_df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IugHXczZCH4G"},"outputs":[],"source":["cleaned_df.repartition(1).write.format('csv').option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").save(\"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/acm_1995_2004_specialCharsTitle.csv\", mode='overwrite')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qx7_nTOrHORF"},"outputs":[],"source":["from pyspark.sql.functions import length, col\n","\n","# Define the length condition (e.g., filter strings with length greater than 3)\n","length_condition = filtered_df[\"year\"] == '2004'\n","\n","# Apply the filter\n","filtered = filtered_df.filter(length_condition)\n","\n","# Show the result\n","filtered.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1706367056617,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"IS_-gfNCHON6","outputId":"df167344-164f-48ff-885b-3b0cc2a7887b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Title: Tâ„¢he @Qu.iFAÃ‡AD:Eck, (Br;Ä,Üo-wn) Fo_x Ju\\mps - Oveâ€”r The Laz,a,y Dog isn't  DataMIMEâ„!\n","Cleaned Title: Tâhe QuiFAÃADEck, BrÄ,Üown Fo_x Jumps  Oveâr The Laz,a,y Dog isnt  DataMIMEâ\n"]}],"source":["# @title\n","import re\n","\n","# Define a sample title with special characters\n","title = \"Tâ„¢he @Qu.iFAÃ‡AD:Eck, (Br;Ä,Üo-wn) Fo_x Ju\\\\mps - Oveâ€”r The Laz,a,y Dog isn't  DataMIMEâ„!\"\n","\n","# Remove special characters from the title while retaining commas\n","cleaned_title = re.sub(r'[^\\w,\\s]', '', title)\n","\n","# Print the cleaned title\n","print(\"Original Title:\", title)\n","print(\"Cleaned Title:\", cleaned_title)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"468m_q29HOKg"},"outputs":[],"source":["from pyspark.sql.functions import floor\n","from pyspark.sql.functions import collect_list, explode, udf\n","\n","num_buckets = 4\n","\n","# Calculate the range for each bucket\n","year_range = (2004 - 1995) / num_buckets\n","\n","# Assign each entry to one or more buckets based on blocking keys (year ranges)\n","blocked_df = cleaned_df.withColumn(\"bucket\", floor((col(\"year\").cast(\"int\") - 1995) / year_range))\n","\n","# Group records into blocks based on the buckets\n","blocked_data = blocked_df.groupBy(\"bucket\").agg(collect_list(\"index\").alias(\"block_indices\"), collect_list(\"authors\"))\n","\n","# Show blocked data\n","blocked_data.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1706373398352,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yn6Gl3C9B9Ms","outputId":"bc4d25ce-6351-492b-915d-1078a29f62ec"},"outputs":[{"data":{"text/plain":["69"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["cleaned_df.rdd.getNumPartitions()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125806,"status":"ok","timestamp":1706373686007,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"vN1O0_c0x8m0","outputId":"6debc54c-01fa-4a60-9370-ac97bbe7daf3"},"outputs":[{"data":{"text/plain":["2902"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["df_better_partitioned = cleaned_df.repartition(10)\n","df_better_partitioned.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":100712,"status":"ok","timestamp":1706373808247,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"aQESRyyTzFQY","outputId":"bdb23679-c676-4b52-c4e1-72e11222772c"},"outputs":[{"data":{"text/plain":["2902"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["cleaned_df.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0um906urHOFL"},"outputs":[],"source":["def jaccard_similarity(set1, set2):\n","    intersection = len(set1.intersection(set2))\n","    union = len(set1.union(set2))\n","    return intersection / union if union != 0 else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozS5r1qhHOCT","colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"status":"error","timestamp":1706449364489,"user_tz":-60,"elapsed":13,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"19718e55-345c-4934-9f93-4eefe0236f64"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'udf' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e2a2f26e92b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjaccard_similarity_udf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'udf' is not defined"]}],"source":["jaccard_similarity_udf = udf(jaccard_similarity, IntegerType())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyduK0mgHN_j"},"outputs":[],"source":["# Apply similarity function to all pairs of entities within each bucket\n","matched_pairs = blocked_data.select(\"bucket\", explode(\"block_indices\").alias(\"index1\")) \\\n","    .join(df.withColumnRenamed(\"index\", \"index1\"), col(\"index1\") == col(\"df.index\")) \\\n","    .select(\"bucket\", \"index1\", split(\"authors\", \", \").alias(\"authors1\")) \\\n","    .join(blocked_data.select(\"bucket\", explode(\"block_indices\").alias(\"index2\")), \"bucket\") \\\n","    .join(df.withColumnRenamed(\"index\", \"index2\"), col(\"index2\") == col(\"df.index2\")) \\\n","    .select(\"index1\", \"index2\", split(\"authors\", \", \").alias(\"authors2\")) \\\n","    .select(\"index1\", \"index2\", jaccard_similarity_udf(\"authors1\", \"authors2\").alias(\"similarity\")) \\\n","    .filter(\"index1 != index2\")  # Exclude comparing the same entity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14621,"status":"ok","timestamp":1706540263000,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"GeOa505iGA_z","outputId":"0febcef7-e3de-40ee-fa56-a2111b4e2959"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-levenshtein\n","  Downloading python_Levenshtein-0.23.0-py3-none-any.whl (9.4 kB)\n","Collecting Levenshtein==0.23.0 (from python-levenshtein)\n","  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.1.0 (from Levenshtein==0.23.0->python-levenshtein)\n","  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-levenshtein\n","Successfully installed Levenshtein-0.23.0 python-levenshtein-0.23.0 rapidfuzz-3.6.1\n"]}],"source":["!pip install python-levenshtein"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1706540263588,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"BMO798o3GA9M","outputId":"5b32d3d1-6c9b-4666-f9f8-2d31440679e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":17}],"source":["from Levenshtein import distance, ratio\n","distance('Levenshtein', 'Lenvinsten')"]},{"cell_type":"code","source":["def jaccard_similarity_case_insensitive(str1, str2):\n","    if str1 is None or str2 is None:\n","      return 0.0\n","    set1 = set(str1.lower().split())\n","    set2 = set(str2.lower().split())\n","\n","    intersection = len(set1.intersection(set2))\n","    union = len(set1.union(set2))\n","\n","    similarity = intersection / union if union != 0 else 0\n","    return similarity\n","\n","# Example usage:\n","string1 = \"Fernando Berzal, Nicols Marn\"\n","string2 = \"Fernando Berzal Galiano, Nicols Marn\"\n","print(jaccard_similarity_case_insensitive(string1, string2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4qmVdZlUpha","executionInfo":{"status":"ok","timestamp":1706613753826,"user_tz":-60,"elapsed":386,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"999b187a-2107-4ad3-f933-855989cff659"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5\n"]}]},{"cell_type":"code","source":["# Register the UDF to calculate Jaccard similarity\n","jaccard_similarity_udf = udf(jaccard_similarity_case_insensitive, DoubleType())\n","\n","def find_duplicates_for_ground_truth_js(df1, df2, threshold=0.5):\n","    # Select only the \"title\" and \"authors\" columns from df1 and alias them\n","    df1_subset = df1.select(col(\"title\").alias(\"title_1\"), col(\"authors\").alias(\"authors_1\"))\n","\n","    # Select only the \"title\" and \"authors\" columns from df2 and alias them\n","    df2_subset = df2.select(col(\"title\").alias(\"title_2\"), col(\"authors\").alias(\"authors_2\"))\n","\n","    # Join the subsets of df1 and df2 containing \"title\" and \"authors\" columns\n","    joined_df = df1_subset.crossJoin(df2_subset)\n","\n","    # Calculate the similarity score using Jaccard similarity on \"title\" and \"authors\"\n","    similarity_df = joined_df.withColumn(\"Title_Similarity\", jaccard_similarity_udf(joined_df[\"title_1\"], joined_df[\"title_2\"])) \\\n","                             .withColumn(\"Authors_Similarity\", jaccard_similarity_udf(joined_df[\"authors_1\"], joined_df[\"authors_2\"]))\n","\n","    # Filter the DataFrame to keep only the pairs with similarity scores greater than or equal to the specified threshold\n","    duplicates_df = similarity_df.filter((similarity_df[\"Title_Similarity\"] >= threshold) & (similarity_df[\"Authors_Similarity\"] >= threshold))\n","\n","    # Select and rename the relevant columns\n","    duplicates_df = duplicates_df.select(duplicates_df[\"title_1\"].alias(\"Title1\"),\n","                                         duplicates_df[\"title_2\"].alias(\"Title2\"),\n","                                         duplicates_df[\"authors_1\"].alias(\"Authors1\"),\n","                                         duplicates_df[\"authors_2\"].alias(\"Authors2\"),\n","                                         duplicates_df[\"Title_Similarity\"],\n","                                         duplicates_df[\"Authors_Similarity\"])\n","\n","    return duplicates_df"],"metadata":{"id":"5kyKfUyxHB9x","executionInfo":{"status":"ok","timestamp":1706614006909,"user_tz":-60,"elapsed":372,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706540288837,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"sxNqm3J-SjQK","outputId":"c095558a-f7ad-4170-9aba-632f2536567c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.875, 8)"]},"metadata":{},"execution_count":21}],"source":["ratio(string1, string2), distance(string1, string2)"]},{"cell_type":"code","source":["jaccard_similarity('Tucakov V.', 'tucano v.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"qQFho7pKT62Z","executionInfo":{"status":"error","timestamp":1706449439642,"user_tz":-60,"elapsed":313,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"dc0586a8-f554-43a6-e4f6-7f6108588bdf"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'str' object has no attribute 'intersection'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d7122e6844fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tucakov V.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tucano v.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-144493d1e9f0>\u001b[0m in \u001b[0;36mjaccard_similarity\u001b[0;34m(set1, set2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjaccard_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mintersection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mintersection\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munion\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munion\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'intersection'"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOy2aiDwGA6J"},"outputs":[],"source":["ratio(\"Edwin M. Knorr, Raymond T. Ng, V. Tucakov\", \"Edwin M. Knorr, Raymond T. Ng, Vladimir Tucakov\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zk8mH-CGA3W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706553594473,"user_tz":-60,"elapsed":206,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"473d20b8-e3b7-4b31-c7b8-5a1bed60a047"},"outputs":[{"output_type":"stream","name":"stdout","text":["Amer-YahiaFXS03\n"]}],"source":["def generate_id(title, authors, venue, year):\n","    # Split the authors' names by commas\n","    author_list = authors.split(', ')\n","\n","    # Extract the last name of the first author\n","    first_author_last_name = author_list[0].split()[-1]\n","\n","    # Take the first letter of the last name for other authors\n","    other_authors_initials = ''.join([author.split()[-1][0].capitalize() for author in author_list[1:]])\n","\n","    # Extract the last two digits of the year\n","    year_last_two_digits = str(year)[-2:]\n","\n","    # Concatenate the components to form the id\n","    id_string = f\"{first_author_last_name}{other_authors_initials}{year_last_two_digits}\"\n","\n","    return id_string\n","\n","# Example usage\n","title = \"Phrase Matching in XML\"\n","authors = \"Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava\"\n","venue = \"VLDB\"\n","year = 2003\n","\n","id = generate_id(title, authors, venue, year)\n","print(id)  # Output: \"conf/vldb/AmerFYDS03"]},{"cell_type":"code","source":["def generate_key(title, authors):\n","    # Shorten the title by taking the first word and the first letter of each subsequent word\n","    title_parts = title.split()\n","    shortened_title = '-'.join([word[:1] for word in title_parts])\n","\n","    # Extract initials of authors\n","    author_initials = ''.join([name[0] for name in authors.split()])\n","\n","    # Concatenate the shortened title and author initials to form the key\n","    key = f\"{shortened_title}-{author_initials}\"\n","    return key\n","\n","# Example usage:\n","title_1 = \"Onedimensional and multidimensional substring selectivity estimation\"\n","authors_1 = \"H V Jagadish, Olga Kapitskaia, Raymond T Ng, Divesh Srivastava\"\n","key_1 = generate_key(title_1, authors_1)\n","print(\"Key for Record 1:\", key_1)\n","\n","title_2 = \"MultiDimensional Substring Selectivity Estimation\"\n","authors_2 = \"H V Jagadish, Olga Kapitskaia, Raymond T Ng, Divesh Srivastava\"\n","key_2 = generate_key(title_2, authors_2)\n","print(\"Key for Record 2:\", key_2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbVcUefsk5oq","executionInfo":{"status":"ok","timestamp":1706554533813,"user_tz":-60,"elapsed":226,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"db3b73b3-5458-42e7-abc5-18708eef211f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Key for Record 1: O-a-m-s-s-e-HVJOKRTNDS\n","Key for Record 2: M-S-S-E-HVJOKRTNDS\n"]}]},{"cell_type":"code","source":["def tokenize(text):\n","    \"\"\"\n","    Tokenizes the input text by splitting it into tokens.\n","    \"\"\"\n","    return text.split()\n","\n","def create_blocks(records, token_type):\n","    \"\"\"\n","    Creates blocks based on common tokens shared between titles or authors' names.\n","\n","    Args:\n","    - records: List of records, where each record is a tuple containing (title, authors, venue, year).\n","    - token_type: Type of tokens to use for blocking ('title' or 'author').\n","\n","    Returns:\n","    - Dictionary where keys are tokens and values are lists of records containing that token.\n","    \"\"\"\n","    blocks = {}\n","    for record in records:\n","        title, authors, venue, year = record\n","        tokens = tokenize(title) if token_type == 'title' else tokenize(authors)\n","        for token in tokens:\n","            if token not in blocks:\n","                blocks[token] = []\n","            blocks[token].append(record)\n","    return blocks\n","\n","# Example dataset\n","dataset = [\n","    (\"Phrase Matching in XML\", \"Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava\", \"VLDB\", 2003),\n","    # Add other records from the dataset here\n","]\n","\n","# Create blocks based on author tokens\n","author_blocks = create_blocks(dataset, 'author')\n","\n","# Print the blocks\n","for token, records in author_blocks.items():\n","    print(f\"Block for author token '{token}':\")\n","    for record in records:\n","        print(record)\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"as2em_Oi-NhI","executionInfo":{"status":"ok","timestamp":1706552935628,"user_tz":-60,"elapsed":223,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"f5b1be25-4e21-4308-d884-73061039d18e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Block for author token 'Sihem':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Amer-Yahia,':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Mary':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'F.':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Fernandez,':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Yu':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Xu,':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Divesh':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n","Block for author token 'Srivastava':\n","('Phrase Matching in XML', 'Sihem Amer-Yahia, Mary F. Fernandez, Yu Xu, Divesh Srivastava', 'VLDB', 2003)\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a8EV7qMz-Nex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jpuJEbzY-NcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jCDQScbw-NZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2869,"status":"ok","timestamp":1706371723072,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"avx5LuBCHN8p","outputId":"f5edf423-cdaa-4aa0-be9b-ddc911d90047"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+---+-----+\n","| id|value| id|value|\n","+---+-----+---+-----+\n","|  1|    A|  3|    X|\n","|  1|    A|  4|    Y|\n","|  2|    B|  3|    X|\n","|  2|    B|  4|    Y|\n","+---+-----+---+-----+\n","\n"]}],"source":["# Create two small DataFrames with the same column header\n","df1 = spark.createDataFrame([(1, 'A'), (2, 'B')], ['id', 'value'])\n","df2 = spark.createDataFrame([(3, 'X'), (4, 'Y')], ['id', 'value'])\n","\n","# Perform cross join\n","cross_joined_df = df1.crossJoin(df2)\n","\n","# Show the result\n","cross_joined_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUu1KejkHN0F"},"outputs":[],"source":["from pyspark.sql.functions import col\n","from pyspark.sql.types import DoubleType\n","\n","def levenshtein_ratio(s1, s2):\n","    return ratio(s1, s2)\n","\n","# Register the UDF to calculate Levenshtein ratio\n","levenshtein_ratio_udf = udf(levenshtein_ratio, DoubleType())\n","\n","def find_duplicates(df1, df2, threshold=0.5):\n","    # Select only the \"title\" and \"authors\" columns from df1 and alias them\n","    df1_subset = df1.select(col(\"title\").alias(\"title_1\"), col(\"authors\").alias(\"authors_1\"))\n","\n","    # Select only the \"title\" and \"authors\" columns from df2 and alias them\n","    df2_subset = df2.select(col(\"title\").alias(\"title_2\"), col(\"authors\").alias(\"authors_2\"))\n","\n","    # Join the subsets of df1 and df2 containing \"title\" and \"authors\" columns\n","    joined_df = df1_subset.crossJoin(df2_subset)\n","\n","    # Calculate the similarity score using Levenshtein ratio on \"title\" and \"authors\"\n","    similarity_df = joined_df.withColumn(\"Title_Similarity\", levenshtein_ratio_udf(joined_df[\"title_1\"], joined_df[\"title_2\"])) \\\n","                             .withColumn(\"Authors_Similarity\", levenshtein_ratio_udf(joined_df[\"authors_1\"], joined_df[\"authors_2\"]))\n","\n","    # Filter the DataFrame to keep only the pairs with similarity scores greater than or equal to the specified threshold\n","    duplicates_df = similarity_df.filter((similarity_df[\"Title_Similarity\"] >= threshold) & (similarity_df[\"Authors_Similarity\"] >= threshold))\n","\n","    # Select and rename the relevant columns\n","    duplicates_df = duplicates_df.select(duplicates_df[\"title_1\"].alias(\"Title1\"),\n","                                         duplicates_df[\"title_2\"].alias(\"Title2\"),\n","                                         duplicates_df[\"authors_1\"].alias(\"Authors1\"),\n","                                         duplicates_df[\"authors_2\"].alias(\"Authors2\"),\n","                                         duplicates_df[\"Title_Similarity\"],\n","                                         duplicates_df[\"Authors_Similarity\"])\n","\n","    return duplicates_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQLF-zoLaaCS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCDLdhBzaZ_Y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1n-8SQyaZ8j"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgYwCjywaZ5f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qC6nbG9Ph0Lz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIHjQjinh0Ik"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4z3QumPhUVAV"},"outputs":[],"source":["\n","data = rdd.map(lambda x: tuple(\n","    field[2:].split('\\n') if field.startswith('#%') else\n","    field[6:] if field.startswith('#index') else\n","    field[2:].split(',') if field.startswith(\"#@\") else\n","    field[2:]\n","    for field in filter(None, x[1].split('\\n'))\n","))\n","\n","data = data.map(lambda x: {\"title\": x[0], \"authors\": x[1], \"year\": x[2], \"journal\": x[3], \"index\": x[4], \"refid\": [item for sublist in x[5:] for item in sublist]})\n","\n","# Define the schema\n","schema = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"authors\", ArrayType(StringType(), True)),\n","    StructField(\"year\", StringType(), True),\n","    StructField(\"journal\", StringType(), True),\n","    StructField(\"index\", StringType(), True),\n","    StructField(\"refid\", ArrayType(StringType(), True)),\n","])\n","\n","# # Apply the schema to the RDD 'a'\n","df = spark.createDataFrame(data, schema=schema)\n","\n","#df.write.format(\"noop\").mode(\"overwrite\").save()\n","\n","# # Show the DataFrame\n","#df.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ch3n2QBB6H7"},"outputs":[],"source":["data = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    field\n","    for field in filter(None, x[1].split('\\n')) if not field.startswith('#%')\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWpOUcNE8RJD"},"outputs":[],"source":["data = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    (\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#*')), None),  # Paper Title\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#@')), None),  # Authors\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#t')), None),  # Year\n","        next((field[2:] for field in x[1].splitlines() if field.startswith('#c')), None),  # Publication Venue\n","        next((field[6:] for field in x[1].splitlines() if field.startswith('#index')), None)  # Index ID\n","    )\n","))\n","\n","for el in data.take(5):\n","    print(el)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AbrmSZQp9Guh"},"outputs":[],"source":["example_string = '''#*Report on the First \"XQuery Implementation, Experience, and Perspectives\" Workshop (XIME-P).\n","#@Ioana Manolescu, Yannis Papakonstantinou\n","#t2004\n","#cSIGMOD Record\n","#index53e9b152b7602d9703bd3739'''\n","\n","for el in example_string.splitlines():\n","    print(el)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfTj8CmnPBVK"},"outputs":[],"source":["for el in rdd.take(5):\n","    print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lr-P4ZOfPluB"},"outputs":[],"source":["\n","\n","# for el in string.split('\\n'):\n","#   if el.startswith(\"#*\") or el.rfind(\" \\\" \"):\n","#     print(el[2:])\n","#   elif el.startswith(\"#@\"):\n","#     print(el[2:])\n","#   elif el.startswith(\"#t\"):\n","#     print(el[2:])\n","#   elif el.startswith(\"#c\"):\n","#     print(el[2:])\n","#   elif el.startswith(\"#index\"):\n","#     print(el[6:])\n","#   else:\n","#     print(None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDhV3Y1XLUkW"},"outputs":[],"source":["data = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    (\n","        next((field[2:] for field in str(x[1]).split('\\n') if field.startswith('#*')), None),  # Paper Title\n","        next((field[2:] for field in x[1].split('\\n') if field.startswith('#@')), None),  # Authors\n","        next((field[2:] for field in x[1].split('\\n') if field.startswith('#t')), None),  # Year\n","        next((field[2:] for field in x[1].split('\\n') if field.startswith('#c')), None),  # Publication Venue\n","        next((field[6:] for field in x[1].split('\\n') if field.startswith('#index')), None)  # Index ID\n","    )\n","))\n","\n","for el in data.take(5):\n","    print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeV1GPOuIsCg"},"outputs":[],"source":["for el in data.take(5):\n","  print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5VRirm_UAuD"},"outputs":[],"source":["data_task1 = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    extract_value(field, '#*',2) if field.startswith('#*') else  # title\n","    extract_value(field, '#@', 2) if field.startswith('#@') else  # authors\n","    extract_value(field, '#t', 2) if field.startswith('#t') else  # year\n","    extract_value(field, '#c', 2) if field.startswith('#c') else  # venue\n","    extract_value(field, '#index', 6) if field.startswith('#index') else None  # id\n","    for field in filter(None, x[1].split('\\n'))\n","))\n","\n","def extract_value(field, marker, idx):\n","    return field[idx:] if field.startswith(marker) else None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhAosMytUwJz"},"outputs":[],"source":["for el in data_task1.take(5):\n","  print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5y43FWSdF8g"},"outputs":[],"source":["for el in rdd.take(5):\n","  print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNAsZb1ApMiO"},"outputs":[],"source":["data_task1 = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","    field[2:] if field.startswith('#*') else # title\n","    field[2:] if field.startswith('#@') else  # authors\n","    field[2:] if field.startswith('#t') else  # year\n","    field[2:] if field.startswith('#c') else  # venue\n","    field[6:] if field.startswith('#index') else # id\n","    None\n","    for field in filter(None, x[1].split('\\n')) if not field.startswith('#%')\n","))\n","for el in data_task1.take(9):\n","  print(el)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bj6RFFxUYvVL"},"outputs":[],"source":["contains_none = data_task1.filter(lambda x: None in x).count() > 0\n","if contains_none:\n","    print(\"data_task1 contains at least one None value.\")\n","else:\n","    print(\"data_task1 does not contain any None values.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZTGo4SKXqoA"},"outputs":[],"source":["# Define the schema\n","schema1 = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"authors\", StringType(), True),\n","    StructField(\"year\", StringType(), True),\n","    StructField(\"journal\", StringType(), True),\n","    StructField(\"index\", StringType(), True),\n","])\n","\n","# # Apply the schema to the RDD 'a'\n","df1 = spark.createDataFrame(data, schema=schema1)\n","\n","#df.write.format(\"noop\").mode(\"overwrite\").save()\n","\n","# # Show the DataFrame\n","df1.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aVV3pUuo3z7"},"outputs":[],"source":["# # Find the maximum length of any tuple\n","# max_length = data.map(len).max()\n","\n","# # Pad the tuples with null values to match the maximum length\n","# padded_data = data.map(lambda x: x + (None,) * (max_length - len(x)))\n","\n","# # Create a schema with fields corresponding to the maximum length\n","# schema2 = StructType([\n","#     StructField(f\"field_{i+1}\", StringType(), True)\n","#     for i in range(max_length)\n","# ])\n","\n","da = data.map(lambda x: {\"title\": x[0], \"authors\": x[1], \"year\": x[2], \"journal\": x[3], \"index\": x[4]})\n","\n","# Create DataFrame with inferred schema and padded data\n","df2 = spark.createDataFrame(da, schema=schema1)\n","df2.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7s0p-Z-Epv7D"},"outputs":[],"source":["df2.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8dgfDzExd_A"},"outputs":[],"source":["# data_task1 = rdd.map(lambda x: tuple(\n","#     field[6:] if field.startswith('#index') else\n","#     field[2:]\n","#     for field in filter(None, x[1].split('\\n'))\n","# ))\n","\n","# # Debugging print statement\n","# print(\"Data from data_task1:\")\n","# print(data_task1.take(5))\n","\n","# # Filter data based on publication year and venue\n","# data_1 = data_task1.filter(lambda x: x[2].isdigit() and 1995 <= int(x[2]) <= 2004 and any(venue.lower() in x[3].lower() for venue in [\"SIGMOD\", \"VLDB\"]))\n","\n","# Debugging print statement\n","#print(\"Data after filtering:\")\n","#print(data_1.take(5))\n","\n","#data_1 = data_task1.map(lambda x: {\"title\": x[0], \"authors\": x[1], \"year\": x[2], \"journal\": x[3], \"index\": x[4]})\n","\n","# Define the schema\n","schema1 = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"authors\", StringType(), True),\n","    StructField(\"year\", StringType(), True),\n","    StructField(\"journal\", StringType(), True),\n","    StructField(\"index\", StringType(), True),\n","])\n","\n","# # Apply the schema to the RDD 'a'\n","df1 = spark.createDataFrame(data_task1, schema=schema1)\n","\n","#df.write.format(\"noop\").mode(\"overwrite\").save()\n","\n","# # Show the DataFrame\n","df1.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gs4D4Bw4Ib2N"},"outputs":[],"source":["# Filter publications between 1995 and 2004 in VLDB and SIGMOD venues\n","filtered_df = df2.filter(\n","    (col(\"year\").cast(\"int\").between(1995, 2004)) &\n","    (col(\"journal\").rlike(\"(?i)SIGMOD|VLDB\"))\n",")\n","\n","# # Concatenate authors array into a single string separated by a comma\n","# filtered_df = filtered_df.withColumn(\"authors_str\", concat_ws(\", \", col(\"authors\")))\n","\n","# # Select the required columns\n","# selected_columns = [\"index\", \"title\", \"authors_str\", \"journal\", \"year\"]\n","# filtered_df = filtered_df.select(selected_columns)\n","\n","filtered_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahg_m4cInZAI"},"outputs":[],"source":["\n","from pyspark.sql.functions import length, col\n","\n","# Define the length condition (e.g., filter strings with length greater than 5)\n","length_condition = length(filtered_df[\"year\"]) > 4\n","\n","# Apply the filter\n","filtered = filtered_df.filter(length_condition)\n","\n","# Show the result\n","filtered.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e3bjr5IpSFx"},"outputs":[],"source":["from pyspark.sql.functions import length, col\n","# Define the length condition using col(\"column_name\")\n","length_condition = length(col(\"year\")) > 5\n","\n","# Apply the filter\n","filtered = filtered_df.filter(length_condition)\n","\n","# Show the result\n","filtered.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vpOwF8rYpofN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xAXlmNPOx1k"},"outputs":[],"source":["# Write the result to CSV files\n","filtered_df.write.csv(\"/content/gdrive/MyDrive/DBLP_1995_2004_test.csv\", header=True, mode=\"overwrite\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNPTKFEvUEII"},"outputs":[],"source":["filtered_df.repartition(1).write.csv(\"/content/gdrive/MyDrive/DBLP_1995_2004_test3.csv\", header=True, mode=\"overwrite\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbzzBkOIDGdi"},"outputs":[],"source":["\n","# Select the required columns\n","selected_columns = [\"index\", \"title\", \"authors\", \"journal\", \"year\"]\n","filtered_df = filtered_df.select(selected_columns)\n","\n","\n","\n","# # Write the result to CSV files\n","filtered_df.write.csv(\"/content/gdrive/MyDrive/DBLP_1995_2004.csv\", header=True, mode=\"overwrite\")\n","\n","# # Additional filtering for ACM venue\n","# acm_filtered_df = df.filter(\n","#     (col(\"year\").cast(\"int\").between(1995, 2004)) &\n","#     (col(\"journal\").rlike(\"(?i)ACM\"))\n","# )\n","\n","# acm_filtered_df = acm_filtered_df.select(selected_columns)\n","# # acm_filtered_df.write.csv(\"ACM_1995_2004.csv\", header=True, mode=\"overwrite\")\n","\n","# Stop the Spark session\n","#spark.stop()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"92M25x4kpwza"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKodmzthbKRZrOCKaKQBW5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}