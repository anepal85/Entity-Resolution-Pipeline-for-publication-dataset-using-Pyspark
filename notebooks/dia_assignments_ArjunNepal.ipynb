{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1706903269438,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yG4NFSSoiE2c","outputId":"cbffb2cf-d81b-4ac9-a6a4-59c3624f845e"},"outputs":[{"output_type":"stream","name":"stdout","text":["java-1.11.0-openjdk-amd64  java-11-openjdk-amd64\n"]}],"source":["!ls /usr/lib/jvm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fjVQZm7rijIQ","executionInfo":{"status":"ok","timestamp":1706903269438,"user_tz":-60,"elapsed":7,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["# !apt-get update\n","# !apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"etzsx0Fzj_Cr","executionInfo":{"status":"ok","timestamp":1706903269439,"user_tz":-60,"elapsed":8,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["# !wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n","#  # Unzip file\n","# !tar -xvzf spark-3.5.0-bin-hadoop3.tgz"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13340,"status":"ok","timestamp":1706903282773,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"clqxjHynkcmU","outputId":"d1f2ff87-f95f-41f7-8ed7-42786ef28959"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"]}],"source":["#!pip install -q findspark\n","!pip install pyspark"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11729,"status":"ok","timestamp":1706903294492,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"F3-bQEZ3QZXs","outputId":"8137059b-4976-453b-e708-77cd87feb9cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: python-levenshtein in /usr/local/lib/python3.10/dist-packages (0.24.0)\n","Requirement already satisfied: Levenshtein==0.24.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein) (0.24.0)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.24.0->python-levenshtein) (3.6.1)\n"]}],"source":["!pip install python-levenshtein"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"yslhrL1ajiWv","executionInfo":{"status":"ok","timestamp":1706908226593,"user_tz":-60,"elapsed":229,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["from pyspark.sql.session import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n","from pyspark.sql.functions import split\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql.functions import col, concat_ws, substring, row_number, concat\n","from pyspark.sql.functions import lower, count, when, lit\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import regexp_replace, regexp_extract, collect_list, explode, udf\n","from pyspark.sql.types import DoubleType, BooleanType\n","from pyspark.sql.functions import monotonically_increasing_id\n","from pyspark.sql.functions import array\n","from collections import Counter\n","import math\n","import time\n","from Levenshtein import distance, ratio\n","import os"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1706903297826,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"8p-VjPhzy8WY","outputId":"e78bfdf6-0962-45ee-c0fb-d0981a57c823"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1706903297826,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"yP2gSg3Cc6Xi","outputId":"ef7df82a-d4d9-4bd0-ac21-225eb53bc556"},"outputs":[{"output_type":"stream","name":"stdout","text":[" acm_1995_2004.csv\t\t  dblp_1995_2004.csv\t     match_blocked_dblp_acm_1995_2004.csv\n"," acm_resolved.csv\t\t  dblp.txt\t\t     match_dblp_acm_1995_2004.csv\n"," acm.txt\t\t\t  dia_assignments.ipynb      Matched_Entities.csv\n","'Copy of dia_assignments.ipynb'   dia_assignments_v2.ipynb\n"]}],"source":["!ls /content/gdrive/MyDrive/'Colab Notebooks'/Dia_Exercise/"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1706903298162,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"},"user_tz":-60},"id":"LUk0qWOY_zoM","outputId":"4b87767c-89b4-4895-a39c-91c3107ca92a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/TestMamun.txt\n"]}],"source":["!ls /content/gdrive/MyDrive/TestMamun.txt"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"SBVofdjCdoPM","executionInfo":{"status":"ok","timestamp":1706903298163,"user_tz":-60,"elapsed":8,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["file_path_dblp = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/dblp.txt\"\n","file_path_acm = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/acm.txt\""]},{"cell_type":"code","source":["csv_dlp = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/dblp_1995_2004.csv\"\n","csv_acm = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/acm_1995_2004.csv\""],"metadata":{"id":"9WgAybZ7IUAE","executionInfo":{"status":"ok","timestamp":1706903298163,"user_tz":-60,"elapsed":7,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"SED3QOxKUX2-","executionInfo":{"status":"ok","timestamp":1706903298163,"user_tz":-60,"elapsed":7,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["file_path = \"/content/gdrive/MyDrive/TestMamun_2.txt\""]},{"cell_type":"code","execution_count":13,"metadata":{"id":"SLHnRBgst2tv","executionInfo":{"status":"ok","timestamp":1706903311752,"user_tz":-60,"elapsed":13595,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["spark = SparkSession.builder.appName(\"RDDPrintExample\").getOrCreate()\n","\n","# # Define the custom delimiter\n","# delimiter = \"\\n\\n\"\n","\n","# # Create an RDD using newAPIHadoopFile with TextInputFormat\n","# rdd = spark.sparkContext.newAPIHadoopFile(\n","#     file_path,\n","#     \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n","#     \"org.apache.hadoop.io.LongWritable\",\n","#     \"org.apache.hadoop.io.Text\",\n","#     conf={\"textinputformat.record.delimiter\": delimiter},\n","# )\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"NBl0vHoOzHsj","executionInfo":{"status":"ok","timestamp":1706903311753,"user_tz":-60,"elapsed":34,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["# Define the schema\n","pub_schema = StructType([\n","    StructField(\"title\", StringType(), True),\n","    StructField(\"authors\", StringType(), True),\n","    StructField(\"year\", StringType(), True),\n","    StructField(\"journal\", StringType(), True),\n","    StructField(\"index\", StringType(), True),\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8b8nylLp2TF-","executionInfo":{"status":"ok","timestamp":1706903311753,"user_tz":-60,"elapsed":26,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def create_dataframe_from_file(file_path, pub_schema):\n","    # Define the custom delimiter\n","    delimiter = \"\\n\\n\"\n","\n","    # Create an RDD using newAPIHadoopFile with TextInputFormat\n","    rdd = spark.sparkContext.newAPIHadoopFile(\n","        file_path,\n","        \"org.apache.hadoop.mapreduce.lib.input.TextInputFormat\",\n","        \"org.apache.hadoop.io.LongWritable\",\n","        \"org.apache.hadoop.io.Text\",\n","        conf={\"textinputformat.record.delimiter\": delimiter},\n","    )\n","\n","    # Filter and map the RDD to extract relevant fields\n","    data_rdd = rdd.filter(lambda x: not x[1].startswith('#%')).map(lambda x: tuple(\n","        (\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#*')), None),  # Paper Title\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#@')), None),  # Authors\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#t')), None),  # Year\n","            next((field[2:] for field in x[1].splitlines() if field.startswith('#c')), None),  # Publication Venue\n","            next((field[6:] for field in x[1].splitlines() if field.startswith('#index')), None)  # Index ID\n","        )\n","    ))\n","\n","    # Create DataFrame using the defined schema\n","    df = spark.createDataFrame(data_rdd, schema=pub_schema)\n","\n","    return df\n","\n","# df = create_dataframe_from_file(file_path, pub_schema)\n","# df.show(truncate=False)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"TL2at22F3G3r","executionInfo":{"status":"ok","timestamp":1706903311754,"user_tz":-60,"elapsed":24,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def filter_and_clean_df(df):\n","    # Filter publications between 1995 and 2004 in VLDB and SIGMOD venues\n","    filtered_df = df.filter(\n","        (col(\"year\").cast(\"int\").between(1995, 2004)) &\n","        (col(\"journal\").rlike(\"(?i)SIGMOD|VLDB\"))\n","    )\n","    # # Clean the journal column\n","    # cleaned_df = filtered_df.withColumn(\"journal\",\n","    #                                     regexp_replace(\n","    #                                         regexp_replace(\"journal\", \"(?i).*\\\\bVLDB\\\\b.*\", \"VLDB\"),\n","    #                                         \"(?i).*\\\\bSIGMOD\\\\b.*\", \"SIGMOD\"))\n","\n","    return filtered_df"]},{"cell_type":"code","source":["def remove_null_rows(dataframe):\n","    return dataframe.dropna()"],"metadata":{"id":"ikZs-b0nKAWi","executionInfo":{"status":"ok","timestamp":1706903311754,"user_tz":-60,"elapsed":21,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":18,"metadata":{"id":"RTvEUUva3pGV","executionInfo":{"status":"ok","timestamp":1706903311755,"user_tz":-60,"elapsed":19,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def remove_special_chars(df):\n","    # Remove special characters and replace with single space\n","    pattern = r'[^\\wÄÖÜäöü,]|(\\s{2,})'\n","    df = df.withColumn(\"title\", regexp_replace(\"title\", pattern, ' ')).withColumn(\"authors\", regexp_replace(\"authors\", pattern, ' '))\n","    return df\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"xxSITF3Q4FtD","executionInfo":{"status":"ok","timestamp":1706903311755,"user_tz":-60,"elapsed":17,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def write_to_csv(dataframe, path):\n","  dataframe.repartition(1).write.format('csv').option(\"header\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").save(path, mode='overwrite')"]},{"cell_type":"code","source":["def remove_inter_duplicates(df):\n","    # Convert titles, authors, and year to lowercase for case-insensitive comparison\n","    df = df.withColumn(\"lower_title\", lower(col(\"title\"))) \\\n","           .withColumn(\"lower_authors\", lower(col(\"authors\")))\n","\n","    # Find duplicates using window function\n","    windowSpec = Window.partitionBy(\"lower_title\", \"lower_authors\", \"year\", \"index\")\n","    df_with_count = df.withColumn(\"count\", count(\"*\").over(windowSpec))\n","\n","    # # Filter only rows with count > 1, indicating duplicates\n","    # duplicates_df = df_with_count.filter(col(\"count\") > 1).orderBy(col(\"count\").desc()) \\\n","    #                              .drop(\"lower_title\", \"lower_authors\")\n","\n","    # Remove duplicates from original DataFrame\n","    df_unique = df_with_count.filter(col(\"count\") == 1).drop(\"count\", \"lower_title\", \"lower_authors\")\n","\n","    return df_unique"],"metadata":{"id":"c0g2D4PEKRsj","executionInfo":{"status":"ok","timestamp":1706906145897,"user_tz":-60,"elapsed":249,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def pipeline(txt_file_path, *funcs):\n","    df = create_dataframe_from_file(txt_file_path, pub_schema)\n","    for func in funcs:\n","        df = func(df)\n","    return df\n","df_acm = pipeline(file_path_acm, remove_null_rows, filter_and_clean_df, remove_special_chars, remove_inter_duplicates)\n","df_dlp = pipeline(file_path_dblp, remove_null_rows, filter_and_clean_df, remove_special_chars, remove_inter_duplicates)"],"metadata":{"id":"JmFcO9XsKZ2Z","executionInfo":{"status":"ok","timestamp":1706903318494,"user_tz":-60,"elapsed":6754,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#write_to_csv(df_acm, csv_acm)\n","#write_to_csv(df_dlp, csv_dlp)"],"metadata":{"id":"27ROXOrPL1T1","executionInfo":{"status":"ok","timestamp":1706903318495,"user_tz":-60,"elapsed":17,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"zZHS5lkGP3WJ","executionInfo":{"status":"ok","timestamp":1706903319380,"user_tz":-60,"elapsed":897,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"outputs":[],"source":["def read_csv_with_schema(spark, file_path, schema):\n","    \"\"\"\n","    Read records from a CSV file using a specified schema.\n","\n","    Args:\n","    - spark: SparkSession object\n","    - file_path: path to the CSV file\n","    - schema: schema to be applied to the DataFrame\n","\n","    Returns:\n","    - DataFrame containing the records from the CSV file with the specified schema\n","    \"\"\"\n","    # Read CSV file with schema\n","    df = spark.read.csv(file_path, schema=schema, header=True, encoding=\"UTF-8\")\n","    return df\n","df_acm = read_csv_with_schema(spark, csv_acm, pub_schema)\n","df_dlp = read_csv_with_schema(spark, csv_dlp, pub_schema)"]},{"cell_type":"code","source":["ground_truth_duplicates_path = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/match_dblp_acm_1995_2004.csv\"\n","blocked_duplicates_path = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/Matched_Entities.csv\"\n","resolved_data_path = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/Resolved_Entities.csv\""],"metadata":{"id":"5jhB3ROA8Gqw","executionInfo":{"status":"ok","timestamp":1706903319380,"user_tz":-60,"elapsed":14,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def measure_execution_time(func):\n","    def wrapper(*args, **kwargs):\n","        start_time = time.time()\n","        result = func(*args, **kwargs)\n","        end_time = time.time()\n","        execution_time = end_time - start_time\n","        print(f\"Execution time of {func.__name__}: {execution_time} seconds\")\n","        return result\n","    return wrapper"],"metadata":{"id":"pNR9_Xbt9BFP","executionInfo":{"status":"ok","timestamp":1706906212495,"user_tz":-60,"elapsed":6,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["@measure_execution_time\n","def matching_without_blocking(df1, df2, similarity_func, filter_func, output_path = None, threshold=0.5):\n","  sim_udf = udf(similarity_func, DoubleType())\n","  filter_udf = udf(filter_func, BooleanType())\n","\n","  duplicates = find_duplicates_for_ground_truth_js(df1, df2, sim_udf, filter_udf, threshold)\n","\n","  if output_path is not None:\n","    write_to_csv(duplicates, output_path)\n","  return duplicates"],"metadata":{"id":"8CF9Qy142vZY","executionInfo":{"status":"ok","timestamp":1706903319381,"user_tz":-60,"elapsed":12,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def jaccard_similarity_case_insensitive(str1, str2):\n","    if str1 is None or str2 is None:\n","      return 0.0\n","    set1 = set(str1.lower().split())\n","    set2 = set(str2.lower().split())\n","\n","    intersection = len(set1.intersection(set2))\n","    union = len(set1.union(set2))\n","\n","    similarity = intersection / union if union != 0 else 0\n","    return similarity"],"metadata":{"id":"NV6cMXj6RgW1","executionInfo":{"status":"ok","timestamp":1706903319381,"user_tz":-60,"elapsed":11,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def trigram_similarity(s1, s2):\n","    # Function to generate trigrams from a string\n","    def generate_trigrams(string):\n","        return [string[i:i+3] for i in range(len(string) - 2)]\n","\n","    # Generate trigrams for both strings\n","    trigrams_s1 = generate_trigrams(s1.lower())\n","    trigrams_s2 = generate_trigrams(s2.lower())\n","\n","    # Calculate Jaccard similarity coefficient\n","    intersection = len(set(trigrams_s1) & set(trigrams_s2))\n","    union = len(set(trigrams_s1) | set(trigrams_s2))\n","    similarity = intersection / union if union != 0 else 0\n","\n","    return similarity"],"metadata":{"id":"vCJBHTt80HkS","executionInfo":{"status":"ok","timestamp":1706903319382,"user_tz":-60,"elapsed":11,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def cosine_similarity(s1, s2):\n","    # Function to preprocess and tokenize strings\n","    def preprocess(text):\n","        return text.lower().split()\n","\n","    # Tokenize the strings\n","    tokens1 = preprocess(s1)\n","    tokens2 = preprocess(s2)\n","\n","    # Count the occurrences of each token in both strings\n","    counter1 = Counter(tokens1)\n","    counter2 = Counter(tokens2)\n","\n","    # Compute the dot product of the token counts\n","    dot_product = sum(counter1[token] * counter2[token] for token in counter1.keys() & counter2.keys())\n","\n","    # Compute the Euclidean norm of the token counts\n","    norm1 = math.sqrt(sum(counter1[token] ** 2 for token in counter1.keys()))\n","    norm2 = math.sqrt(sum(counter2[token] ** 2 for token in counter2.keys()))\n","\n","    # Compute the cosine similarity\n","    similarity = dot_product / (norm1 * norm2) if (norm1 * norm2) != 0 else 0\n","\n","    return similarity"],"metadata":{"id":"jTLAx2CC-w6U","executionInfo":{"status":"ok","timestamp":1706906224588,"user_tz":-60,"elapsed":9,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["def filter_duplicates(title_similarity, author_similarity, threshold, sameyear, threshold2 = 0.75):\n","    if (title_similarity == 1 and author_similarity >= threshold and sameyear == 1) or \\\n","       (title_similarity >= threshold and author_similarity == 1 and sameyear == 1) or \\\n","       (title_similarity >= threshold2 and author_similarity >= threshold2):  ### Not same year pub shoud have\n","       #atleast 75 percent similarity between years and authors\n","        return True\n","    else:\n","        return False"],"metadata":{"id":"hSqkGo3Y-42z","executionInfo":{"status":"ok","timestamp":1706906122422,"user_tz":-60,"elapsed":258,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["# Register the UDF to calculate Jaccard similarity\n","#jaccard_similarity_udf = udf(jaccard_similarity_case_insensitive, DoubleType())\n","\n","def find_duplicates_for_ground_truth_js(df1, df2,jaccard_similarity_udf, filter_duplicates_udf, threshold=0.5):\n","    # Select only the \"title\" and \"authors\" columns from df1 and alias them\n","    df1_subset = df1.select(col(\"title\").alias(\"title_1\"), col(\"authors\").alias(\"authors_1\"), col(\"year\").alias(\"year_1\"))\n","\n","    # Select only the \"title\" and \"authors\" columns from df2 and alias them\n","    df2_subset = df2.select(col(\"title\").alias(\"title_2\"), col(\"authors\").alias(\"authors_2\"), col(\"year\").alias(\"year_2\"))\n","\n","    # Join the subsets of df1 and df2 containing \"title\" and \"authors\" columns\n","    joined_df = df1_subset.crossJoin(df2_subset)\n","\n","    # Calculate the similarity score using Jaccard similarity on \"title\" and \"authors\"\n","    similarity_df = joined_df.withColumn(\"Title_Similarity\", jaccard_similarity_udf(joined_df[\"title_1\"], joined_df[\"title_2\"])) \\\n","                             .withColumn(\"Authors_Similarity\", jaccard_similarity_udf(joined_df[\"authors_1\"], joined_df[\"authors_2\"]))\\\n","                             .withColumn(\"Years_Similarity\", when(joined_df[\"year_1\"] == joined_df[\"year_2\"], lit(1)).otherwise(lit(0)))\n","\n","    # Filter the DataFrame to keep only the pairs with similarity scores meeting the refined criteria\n","    duplicates_df = similarity_df.filter(filter_duplicates_udf(similarity_df[\"Title_Similarity\"],\n","                                                          similarity_df[\"Authors_Similarity\"],\n","                                                          lit(threshold), similarity_df[\"Years_Similarity\"]))\n","\n","    # Select and rename the relevant columns\n","    duplicates_df = duplicates_df.select(duplicates_df[\"title_1\"].alias(\"Title1\"),\n","                                         duplicates_df[\"title_2\"].alias(\"Title2\"),\n","                                         duplicates_df[\"authors_1\"].alias(\"Authors1\"),\n","                                         duplicates_df[\"authors_2\"].alias(\"Authors2\"),\n","                                         duplicates_df[\"Title_Similarity\"],\n","                                         duplicates_df[\"Authors_Similarity\"],\n","                                         duplicates_df[\"year_1\"].alias(\"Year1\"),\n","                                         duplicates_df[\"year_2\"].alias(\"Year2\"))\n","\n","\n","    return duplicates_df"],"metadata":{"id":"Hia6uIzGN-jH","executionInfo":{"status":"ok","timestamp":1706903319382,"user_tz":-60,"elapsed":9,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def generate_blocking_key(title, authors, year):\n","    # Split the authors' names by commas\n","    author_list = authors.split(',')\n","\n","    # Sort author names by last name in ascending order (case-insensitive)\n","    sorted_author_list = sorted(author_list, key=lambda x: x.split()[-1].lower())\n","\n","    print(sorted_author_list)\n","    # Extract the last name of the first author\n","    first_author_last_name = sorted_author_list[0].split()[-1]\n","\n","    # Take the first letter of the last name for other authors\n","    other_authors_initials = ''.join([author.split()[-1][0].capitalize() for author in sorted_author_list[1:]])\n","\n","    # Extract the last two digits of the year\n","    year_last_two_digits = str(year)[2:]\n","\n","    blocking_key = f\"{first_author_last_name}{other_authors_initials}{year_last_two_digits}\"\n","    return blocking_key"],"metadata":{"id":"eSyxXhit0Fqw","executionInfo":{"status":"ok","timestamp":1706903319749,"user_tz":-60,"elapsed":375,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def find_duplicates_with_blocking(df1, df2, jaccard_similarity_udf, blocking_key_func, threshold=0.5):\n","\n","    # Alias all columns in each DataFrame to distinguish them after joining\n","    df1 = df1.select([col(col_name).alias(f\"{col_name}_df1\") for col_name in df1.columns])\n","    df2 = df2.select([col(col_name).alias(f\"{col_name}_df2\") for col_name in df2.columns])\n","\n","    df2 = df2.withColumn(\"id_df2\", monotonically_increasing_id())\n","\n","    # Generate blocking keys for each DataFrame\n","    df1_blocked = df1.withColumn(\"blocking_key_df1\", blocking_key_func(col(\"title_df1\"), col(\"authors_df1\"), col(\"year_df1\")))\n","    df2_blocked = df2.withColumn(\"blocking_key_df2\", blocking_key_func(col(\"title_df2\"), col(\"authors_df2\"), col(\"year_df2\")))\n","\n","    # Join DataFrames on blocking keys\n","    joined_df = df1_blocked.alias(\"df1\").join(df2_blocked.alias(\"df2\"), col(\"df1.blocking_key_df1\") == col(\"df2.blocking_key_df2\"), \"inner\")\n","\n","    # Calculate similarity score using Jaccard similarity on \"title\" and \"authors\" only for records with the same blocking key\n","    similarity_df = joined_df.withColumn(\"Title_Similarity\", when(col(\"df1.blocking_key_df1\") == col(\"df2.blocking_key_df2\"),\n","                                                                   jaccard_similarity_udf(col(\"df1.title_df1\"), col(\"df2.title_df2\"))).otherwise(lit(0))) \\\n","                             .withColumn(\"Authors_Similarity\", when(col(\"df1.blocking_key_df1\") == col(\"df2.blocking_key_df2\"),\n","                                                                     jaccard_similarity_udf(col(\"df1.authors_df1\"), col(\"df2.authors_df2\"))).otherwise(lit(0)))\n","\n","    # Filter the DataFrame to keep only the pairs with similarity scores greater than or equal to the specified threshold\n","    duplicates_df = similarity_df.filter((similarity_df[\"Title_Similarity\"] >= threshold) &\n","                                         (similarity_df[\"Authors_Similarity\"] >= threshold))\n","    matched_df = duplicates_df.drop(*[\"Title_Similarity\", \"Authors_Similarity\", \"title_df2\", \"authors_df2\", \"year_df2\", \"journal_df2\", \"index_df2\"])\n","    return matched_df"],"metadata":{"id":"A3rMGGvZ1yj1","executionInfo":{"status":"ok","timestamp":1706910452660,"user_tz":-60,"elapsed":235,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["@measure_execution_time\n","def matching_with_blocking(df1, df2, similarity_func, blocking_func, output_path = None, threshold=0.5):\n","  sim_udf = udf(similarity_func, DoubleType())\n","  blocking_udf = udf(blocking_func, StringType())\n","\n","  duplicates = find_duplicates_with_blocking(df1, df2, sim_udf, blocking_udf, threshold)\n","\n","  if output_path is not None:\n","    write_to_csv(duplicates, output_path)\n","  return duplicates"],"metadata":{"id":"EZdAsPtmEYww","executionInfo":{"status":"ok","timestamp":1706903319750,"user_tz":-60,"elapsed":9,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["dup_naive = matching_without_blocking(df_acm, df_dlp, cosine_similarity, filter_duplicates, threshold=0.65).cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLEM9I9zVzfD","executionInfo":{"status":"ok","timestamp":1706904156827,"user_tz":-60,"elapsed":587,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"2077f178-b3ba-49d6-d902-018cf55b8d93"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time of matching_without_blocking: 0.20383858680725098 seconds\n"]}]},{"cell_type":"code","source":["dup_naive.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9eQysiOYqjQ","executionInfo":{"status":"ok","timestamp":1706904442981,"user_tz":-60,"elapsed":281129,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"b496e3f5-bf7c-4536-b07a-88906f526c1f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------------------+--------------------+------------------+------------------+-----+-----+\n","|              Title1|              Title2|            Authors1|            Authors2|  Title_Similarity|Authors_Similarity|Year1|Year2|\n","+--------------------+--------------------+--------------------+--------------------+------------------+------------------+-----+-----+\n","|Honey, I shrunk t...|Honey, I Shrunk t...|    Praveen Seshadri|    Praveen Seshadri|0.8432740427115678|0.9999999999999998| 1999| 1999|\n","|lgr  DB  an ODMG ...|lambda DB  An ODM...|Leonidas Fegaras,...|Leonidas Fegaras,...|0.8749999999999998|0.9999999999999998| 2000| 2000|\n","|One size fits all...|One Size Fits All...|     Clark D  French|     Clark D  French|0.9090909090909091|1.0000000000000002| 1995| 1995|\n","|Share your data, ...|Share your data, ...|Irini Fundulaki, ...|Irini Fundulaki, ...|0.9999999999999998|               1.0| 2004| 2004|\n","|1 Safe Algorithms...|1 Safe Algorithms...|Rune Humborstad, ...|Rune Humborstad, ...|0.9999999999999999|0.9999999999999998| 1997| 1997|\n","|3D geographic net...|3D Geographic Net...|Kenneth C  Cox, S...|Kenneth C  Cox, S...|               1.0|0.9999999999999998| 1996| 1996|\n","|A 20 20 Vision of...|A 20 20 Vision of...|S  Misbah Deen, A...|S  Misbah Deen, A...|0.9999999999999998|1.0000000000000002| 2000| 2000|\n","|A Bayesian decisi...|A Bayesian decisi...|V  S  Verykios, G...|Vassilios S  Very...|               1.0|0.7396002616336389| 2003| 2003|\n","|A bi level Bernou...|A Bi Level Bernou...|Peter J  Haas, Ch...|Peter J  Haas, Ch...|0.9999999999999998|0.7999999999999998| 2004| 2004|\n","|A brief survey of...|A Brief Survey of...|Alberto H  F  Lae...|Alberto H  F  Lae...|0.9999999999999998|0.9393364366277241| 2002| 2002|\n","|A Case Based Appr...|A Case Based Appr...|Maurizio Panti, L...|Maurizio Panti, L...|0.9999999999999999|1.0000000000000002| 2000| 2000|\n","|A case for fractu...|A case for fractu...|Ravishankar Ramam...|Ravishankar Ramam...|0.9999999999999998|0.9999999999999999| 2002| 2003|\n","|A case for fractu...|A case for fractu...|Ravishankar Ramam...|Ravishankar Ramam...|0.9999999999999998|0.9999999999999999| 2003| 2003|\n","|A case for intell...|A Case for Intell...|Kimberly Keeton, ...|Kimberly Keeton, ...|1.0000000000000002|0.9999999999999998| 1998| 1998|\n","|A characterizatio...|A Characterizatio...|Frederick R  Reis...|Frederick Reiss, ...|0.9999999999999999|0.8944271909999159| 2003| 2003|\n","|A close look at t...|A Close Look at t...|      Magdy S  Hanna|      Magdy S  Hanna|0.9999999999999998|1.0000000000000002| 1995| 1995|\n","|A comparison of t...|A Comparison of T...|Carl Medsker, Mar...|Carl Medsker, Mar...|               1.0|0.9999999999999999| 1995| 1995|\n","|A complete tempor...|A Complete Tempor...|Debabrata Dey, Te...|Debabrata Dey, Te...|0.9999999999999998|0.9999999999999998| 1996| 1996|\n","|A componentized a...|A Componentized A...|Benny Reich, Isra...|Benny Reich, Isra...|0.9999999999999999|0.9999999999999998| 1998| 1998|\n","|A comprehensive X...|A Comprehensive X...|David DeHaan, Dav...|David DeHaan, Dav...|0.9999999999999998|1.0000000000000002| 2003| 2003|\n","+--------------------+--------------------+--------------------+--------------------+------------------+------------------+-----+-----+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["matched_entities_with_blocking = matching_with_blocking(df_acm, df_dlp,cosine_similarity, generate_blocking_key, threshold=0.65).cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBzQW9tHE2cv","executionInfo":{"status":"ok","timestamp":1706904691564,"user_tz":-60,"elapsed":601,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"9e966f7f-0bea-4d19-9e26-aba4c56673f3"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time of matching_with_blocking: 0.2215595245361328 seconds\n"]}]},{"cell_type":"code","source":["matched_entities_with_blocking.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EY7GaWbrTxAj","executionInfo":{"status":"ok","timestamp":1706904700154,"user_tz":-60,"elapsed":6234,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"8a6c7576-6475-4c52-ee00-8e64f2f50178"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------+--------------------+--------------------+----------------+--------------------+--------------------+--------+-----------------+--------------------+------+----------------+------------------+------------------+\n","|           title_df1|         authors_df1|year_df1|         journal_df1|           index_df1|blocking_key_df1|           title_df2|         authors_df2|year_df2|      journal_df2|           index_df2|id_df2|blocking_key_df2|  Title_Similarity|Authors_Similarity|\n","+--------------------+--------------------+--------+--------------------+--------------------+----------------+--------------------+--------------------+--------+-----------------+--------------------+------+----------------+------------------+------------------+\n","|Honey, I shrunk t...|    Praveen Seshadri|    1999|SIGMOD '99 Procee...|539087f320f70186a...|      Seshadri99|Honey, I Shrunk t...|    Praveen Seshadri|    1999|SIGMOD Conference|53e9990db7602d970...|     0|      Seshadri99|0.8432740427115678|0.9999999999999998|\n","|lgr  DB  an ODMG ...|Leonidas Fegaras,...|    2000|SIGMOD '00 Procee...|5390880220f70186a...|    FegarasMRS00|lambda DB  An ODM...|Leonidas Fegaras,...|    2000|SIGMOD Conference|53e9b0a5b7602d970...|   993|    FegarasMRS00|0.8749999999999998|0.9999999999999998|\n","|One size fits all...|     Clark D  French|    1995|SIGMOD '95 Procee...|539087d420f70186a...|        French95|One Size Fits All...|     Clark D  French|    1995|SIGMOD Conference|53e9afe9b7602d970...|     1|        French95|0.9090909090909091|1.0000000000000002|\n","|Share your data, ...|Irini Fundulaki, ...|    2004|SIGMOD '04 Procee...|5390972920f70186a...|    FundulakiS04|Share your data, ...|Irini Fundulaki, ...|    2004|SIGMOD Conference|53e9af12b7602d970...|  1669|    FundulakiS04|0.9999999999999998|               1.0|\n","|1 Safe Algorithms...|Rune Humborstad, ...|    1997|VLDB '97 Proceedi...|53908a7420f70186a...| HumborstadHRS97|1 Safe Algorithms...|Rune Humborstad, ...|    1997|             VLDB|53e9b241b7602d970...|     2| HumborstadHRS97|0.9999999999999999|0.9999999999999998|\n","|3D geographic net...|Kenneth C  Cox, S...|    1996|   ACM SIGMOD Record|539087dd20f70186a...|         CoxEH96|3D Geographic Net...|Kenneth C  Cox, S...|    1996|    SIGMOD Record|53e9993fb7602d970...|     4|         CoxEH96|               1.0|0.9999999999999998|\n","|A 20 20 Vision of...|S  Misbah Deen, A...|    2000|VLDB '00 Proceedi...|53908a9620f70186a...|      DeenJNNW00|A 20 20 Vision of...|S  Misbah Deen, A...|    2000|             VLDB|53e9a7a6b7602d970...|     5|      DeenJNNW00|0.9999999999999998|1.0000000000000002|\n","|A Bayesian decisi...|V  S  Verykios, G...|    2003|The VLDB Journal ...|53908b4920f70186a...|      ElfekyMV03|A Bayesian decisi...|Vassilios S  Very...|    2003|          VLDB J.|53e9b457b7602d970...|     6|      ElfekyMV03|               1.0|0.7396002616336389|\n","|A bi level Bernou...|Peter J  Haas, Ch...|    2004|SIGMOD '04 Procee...|5390972920f70186a...|         HaasK04|A Bi Level Bernou...|Peter J  Haas, Ch...|    2004|SIGMOD Conference|53e9b891b7602d970...|     7|         HaasK04|0.9999999999999998|0.7999999999999998|\n","|A brief survey of...|Alberto H  F  Lae...|    2002|   ACM SIGMOD Record|5390882d20f70186a...|    LaenderNST02|A Brief Survey of...|Alberto H  F  Lae...|    2002|    SIGMOD Record|53e9aa0fb7602d970...|     8|    LaenderNST02|0.9999999999999998|0.9393364366277241|\n","|A Case Based Appr...|Maurizio Panti, L...|    2000|VLDB '00 Proceedi...|53908a9620f70186a...|     GirettiPS00|A Case Based Appr...|Maurizio Panti, L...|    2000|             VLDB|53e9b917b7602d970...|     9|     GirettiPS00|0.9999999999999999|1.0000000000000002|\n","|A case for fractu...|Ravishankar Ramam...|    2003|The VLDB Journal ...|5390958a20f70186a...|      DeWittRS03|A case for fractu...|Ravishankar Ramam...|    2003|          VLDB J.|53e9ab0eb7602d970...|    10|      DeWittRS03|0.9999999999999998|0.9999999999999999|\n","|A case for intell...|Kimberly Keeton, ...|    1998|   ACM SIGMOD Record|539087ef20f70186a...| HellersteinKP98|A Case for Intell...|Kimberly Keeton, ...|    1998|    SIGMOD Record|53e9a099b7602d970...|    11| HellersteinKP98|1.0000000000000002|0.9999999999999998|\n","|A characterizatio...|Frederick R  Reis...|    2003|Proceedings of th...|53908d6520f70186a...|      KanungoR03|A Characterizatio...|Frederick Reiss, ...|    2003|SIGMOD Conference|53e9a9f7b7602d970...|    12|      KanungoR03|0.9999999999999999|0.8944271909999159|\n","|A close look at t...|      Magdy S  Hanna|    1995|   ACM SIGMOD Record|539087cb20f70186a...|         Hanna95|A Close Look at t...|      Magdy S  Hanna|    1995|    SIGMOD Record|53e9b476b7602d970...|    13|         Hanna95|0.9999999999999998|1.0000000000000002|\n","|A comparison of t...|Carl Medsker, Mar...|    1995|   ACM SIGMOD Record|539087cb20f70186a...| ChristensenMS95|A Comparison of T...|Carl Medsker, Mar...|    1995|    SIGMOD Record|53e9bd1eb7602d970...|    15| ChristensenMS95|               1.0|0.9999999999999999|\n","|A complete tempor...|Debabrata Dey, Te...|    1996|The VLDB Journal ...|53908b4920f70186a...|      BarronDS96|A Complete Tempor...|Debabrata Dey, Te...|    1996|          VLDB J.|53e9ab13b7602d970...|    16|      BarronDS96|0.9999999999999998|0.9999999999999998|\n","|A componentized a...|Benny Reich, Isra...|    1998|   ACM SIGMOD Record|539087f320f70186a...|        ReichS98|A Componentized A...|Benny Reich, Isra...|    1998|    SIGMOD Record|53e9b8a1b7602d970...|    17|        ReichS98|0.9999999999999999|0.9999999999999998|\n","|A comprehensive X...|David DeHaan, Dav...|    2003|Proceedings of th...|53908d6520f70186a...|    ConsensDTÖ03|A Comprehensive X...|David DeHaan, Dav...|    2003|SIGMOD Conference|53e9acd3b7602d970...|    18|    ConsensDTÖ03|0.9999999999999998|1.0000000000000002|\n","|A conceptual arch...|Christoph Bussler...|    2002|   ACM SIGMOD Record|539089d320f70186a...|     BusslerFM02|A Conceptual Arch...|Christoph Bussler...|    2002|    SIGMOD Record|53e99d96b7602d970...|    19|     BusslerFM02|               1.0|1.0000000000000002|\n","+--------------------+--------------------+--------+--------------------+--------------------+----------------+--------------------+--------------------+--------+-----------------+--------------------+------+----------------+------------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["#write_to_csv(matched_entities_with_blocking, blocked_duplicates_path)"],"metadata":{"id":"4R9j0epYr8CC","executionInfo":{"status":"ok","timestamp":1706908052010,"user_tz":-60,"elapsed":245,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["generate_blocking_key_udf = udf(generate_blocking_key)\n","tp_df_dup = dup_naive.withColumn(\"blocking_key_df1\", generate_blocking_key_udf(col(\"Title1\"), col(\"Authors1\"), col(\"Year1\")))"],"metadata":{"id":"pr_uoHXFRTSy","executionInfo":{"status":"ok","timestamp":1706904722743,"user_tz":-60,"elapsed":238,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["#Calculate True Positives (TP)\n","TP = tp_df_dup.join(matched_entities_with_blocking, on=\"blocking_key_df1\", how='inner').count()\n","\n","# Calculate False Positives (FP)\n","FP = TP - matched_entities_with_blocking.count()\n","\n","# Calculate False Negatives (FN)\n","# FN is the number of duplicate pairs identified by the baseline method but not by the blocking method,\n","# which can be calculated as the difference between the total number of duplicate pairs identified by the baseline method and TP\n","FN = TP- tp_df_dup.count()"],"metadata":{"id":"1krQiQlgr77P","executionInfo":{"status":"ok","timestamp":1706904727454,"user_tz":-60,"elapsed":2940,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["TP, FP, FN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADW_qhVSS8KL","executionInfo":{"status":"ok","timestamp":1706904736338,"user_tz":-60,"elapsed":225,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"58992e93-67ae-4d2c-a037-b15c157a2d00"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1664, 166, 57)"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["precision = TP / (TP + FP)\n","\n","recall = TP / (TP + FN)\n","f_score = 2 * (precision * recall) / (precision + recall)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F-score:\", f_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9EMn2y8TmAD","executionInfo":{"status":"ok","timestamp":1706904771209,"user_tz":-60,"elapsed":221,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"2b4f0349-e2d2-479b-a3e7-d59254131b78"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.9092896174863389\n","Recall: 0.9668797210923882\n","F-score: 0.9372007885102789\n"]}]},{"cell_type":"code","source":["def add_alphabets_to_blocking_keys(df, partitionkey):\n","    # Define a window specification to partition by blocking key\n","    window_spec = Window.partitionBy(partitionkey).orderBy(partitionkey)\n","\n","    # Assign unique row numbers within each partition\n","    df = df.withColumn(\"row_num\", row_number().over(window_spec))\n","\n","    # Generate alphabets for unique keys\n","    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n","\n","    # Convert alphabet string to an array of characters\n","    alphabet_array = array([lit(char) for char in alphabet])\n","\n","\n","    # Check if the new blocking key already exists and assign a unique alphabet\n","    df = df.withColumn(\"alphabet\", when(col(\"row_num\") == 1, \"\").otherwise(\n","        alphabet_array.getItem(col(\"row_num\"))\n","    ))\n","\n","    # # Concatenate blocking key with the alphabet to create new blocking keys\n","    df = df.withColumn(\"new_blocking_key\", concat(col(partitionkey), col(\"alphabet\"))).drop(partitionkey)\n","\n","    return df"],"metadata":{"id":"5ixcOO5hp5j4","executionInfo":{"status":"ok","timestamp":1706909452065,"user_tz":-60,"elapsed":255,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["def add_unique_key_to_df(acm, dblp, blocking_key_func, make_unique_blocking_key_func):\n","    blocking_key_func_udf = udf(blocking_key_func, StringType())\n","    dblp = dblp.withColumn(\"idDBLP\", monotonically_increasing_id())\n","\n","    acm = acm.withColumn(\"idACM_notunique\", blocking_key_func_udf(col(\"title\"), col(\"authors\"), col(\"year\")))\n","    acm = add_alphabets_to_blocking_keys(acm, \"idACM_notunique\")\n","\n","    acm = acm.withColumnRenamed(\"idACM_notunique\", \"idACM\")\n","    return acm, dblp\n","df_acm, df_dlp = add_unique_key_to_df(df_acm, df_dlp, generate_blocking_key, add_alphabets_to_blocking_keys)"],"metadata":{"id":"67EkBe6tpfuq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["matches = matching_with_blocking(df_acm, df_dlp,jaccard_similarity_case_insensitive, generate_blocking_key).cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Kos4JlnxakD","executionInfo":{"status":"ok","timestamp":1706910459578,"user_tz":-60,"elapsed":573,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"af04489a-f874-407d-d748-66bbb2fb3896"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Execution time of matching_with_blocking: 0.28238892555236816 seconds\n"]}]},{"cell_type":"code","source":["matches.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34nJZzDTxuAN","executionInfo":{"status":"ok","timestamp":1706910479400,"user_tz":-60,"elapsed":866,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"deef2f35-60f7-4cf0-fcc1-74bf01ecda80"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------+--------------------+--------------------+-----------+------------+--------------------+----------------+----------+------+----------------+\n","|           title_df1|         authors_df1|year_df1|         journal_df1|           index_df1|row_num_df1|alphabet_df1|new_blocking_key_df1|blocking_key_df1|idDBLP_df2|id_df2|blocking_key_df2|\n","+--------------------+--------------------+--------+--------------------+--------------------+-----------+------------+--------------------+----------------+----------+------+----------------+\n","|Visual COKO  a de...|Daniel J  Abadi, ...|    2002|Proceedings of th...|5390882d20f70186a...|          1|            |            AbadiC02|        AbadiC02|      1992|  1992|        AbadiC02|\n","|Aurora  a new mod...|Daniel J  Abadi, ...|    2003|The VLDB Journal ...|5390958a20f70186a...|          1|            |     AbadiCCCELSTZ03| AbadiCCCELSTZ03|       246|   246| AbadiCCCELSTZ03|\n","|Hardware accelera...|Nagender Bandi, C...|    2004|VLDB '04 Proceedi...|53909f8c20f70186a...|          1|            |         AbbadiABS04|     AbbadiABS04|       810|   810|     AbbadiABS04|\n","|Ordered shared lo...|Divyakant Agrawal...|    1995|The VLDB Journal ...|539089bb20f70186a...|          1|            |         AbbadiAJL95|     AbbadiAJL95|      1228|  1228|     AbbadiAJL95|\n","|Efficient integra...|Mirek Riedewald, ...|    2002|Proceedings of th...|5390882d20f70186a...|          1|            |          AbbadiAR02|      AbbadiAR02|       622|   622|      AbbadiAR02|\n","|Applying the gold...|Yi Leh Wu, Divyak...|    2001|SIGMOD '01 Procee...|5390881220f70186a...|          1|            |          AbbadiAW01|      AbbadiAW01|      1971|  1971|      AbbadiAW01|\n","|Tabular placement...|Hailing Yu, Divya...|    2003|VLDB '03 Proceedi...|53909f8c20f70186a...|          1|            |          AbbadiAY03|      AbbadiAY03|      1768|  1768|      AbbadiAY03|\n","|     Guest editorial|Amr El Abbadi, Gu...|    2001|The VLDB Journal ...|5590cef80cf2ce4b6...|          1|            |          AbbadiSW01|      AbbadiSW01|       801|   801|      AbbadiSW01|\n","|Simulation data a...|Ghaleb Abdulla, T...|    2004|   ACM SIGMOD Record|5390962020f70186a...|          1|            |         AbdullaAC04|     AbdullaAC04|      1682|  1682|     AbdullaAC04|\n","|Integrating model...|David J  Abel, Ke...|    1997|   ACM SIGMOD Record|539087dd20f70186a...|          1|            |            AbelKT97|        AbelKT97|       934|   934|        AbelKT97|\n","|Advanced XML data...|         Karl Aberer|    2001|   ACM SIGMOD Record|539089ab20f70186a...|          1|            |            Aberer01|        Aberer01|       133|   133|        Aberer01|\n","|  Book review column|         Karl Aberer|    2001|   ACM SIGMOD Record|558f36690cf2c779a...|          2|           c|           Aberer01c|        Aberer01|       284|   284|        Aberer01|\n","|  Book review column|         Karl Aberer|    2003|   ACM SIGMOD Record|5590d19e0cf237666...|          1|            |            Aberer03|        Aberer03|       286|   286|        Aberer03|\n","|  Book review column|         Karl Aberer|    2003|   ACM SIGMOD Record|5590d19e0cf237666...|          1|            |            Aberer03|        Aberer03|       285|   285|        Aberer03|\n","|  Book review column|         Karl Aberer|    2003|   ACM SIGMOD Record|5590d2bd0cf2ce4b6...|          2|           c|           Aberer03c|        Aberer03|       286|   286|        Aberer03|\n","|  Book review column|         Karl Aberer|    2003|   ACM SIGMOD Record|5590d2bd0cf2ce4b6...|          2|           c|           Aberer03c|        Aberer03|       285|   285|        Aberer03|\n","|Guest editor s in...|         Karl Aberer|    2003|   ACM SIGMOD Record|5390958920f70186a...|          3|           d|           Aberer03d|        Aberer03|       798|   798|        Aberer03|\n","|Report on the fir...|         Karl Aberer|    2003|   ACM SIGMOD Record|53908a4020f70186a...|          4|           e|           Aberer03e|        Aberer03|      1431|  1431|        Aberer03|\n","|P Grid  a self or...|Karl Aberer, Phil...|    2003|   ACM SIGMOD Record|5390958920f70186a...|          1|            |      AbererDDHMPS03|  AbererDDHMPS03|      1234|  1234|  AbererDDHMPS03|\n","|A framework for s...|Karl Aberer, Phil...|    2002|   ACM SIGMOD Record|539089d320f70186a...|          1|            |          AbererHM02|      AbererHM02|        45|    45|      AbererHM02|\n","+--------------------+--------------------+--------+--------------------+--------------------+-----------+------------+--------------------+----------------+----------+------+----------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["def resolve(matches_df, acm, dlp):\n","    matches = matches_df.select(col(\"new_blocking_key_df1\"), col(\"idDBLP_df2\"))\n","    ## TODO\n","    ## How to only get single instance from each dataset using this matches\n","    return matches\n","df_test = resolve(matches, df_acm, df_dlp)"],"metadata":{"id":"TlFpaRH-0IeS","executionInfo":{"status":"ok","timestamp":1706911472709,"user_tz":-60,"elapsed":6,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":92,"outputs":[]},{"cell_type":"code","source":["def resolve_duplicates(matched_entities_with_blocking, df_acm, df_dlp):\n","    # Concatenate resolved entities with matched_entities_to_keep\n","    final_acm = df_acm.drop(\"index\").union(\n","        matched_entities_with_blocking.select(\n","        col(\"title_df1\").alias(\"title\"),\n","        col(\"authors_df1\").alias(\"authors\"),\n","        col(\"year_df1\").alias(\"year\"),\n","        col(\"journal_df1\").alias(\"journal\")\n","        ))\n","    final_dlp = df_dlp.drop(\"index\").union(\n","        matched_entities_with_blocking.select(\n","        col(\"title_df2\").alias(\"title\"),\n","        col(\"authors_df2\").alias(\"authors\"),\n","        col(\"year_df2\").alias(\"year\"),\n","        col(\"journal_df2\").alias(\"journal\")\n","        ))\n","    final_acm.cache()\n","    final_dlp.cache()\n","    return final_acm, final_dlp\n","resolved_acm, resolved_dlp = resolve_duplicates(matched_entities_with_blocking, df_acm, df_dlp)"],"metadata":{"id":"LShVVokvN-YV","executionInfo":{"status":"ok","timestamp":1706904039098,"user_tz":-60,"elapsed":625,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["path_resolved_acm = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/acm_resolved.csv\"\n","path_resolved_dlp = \"/content/gdrive/MyDrive/Colab Notebooks/Dia_Exercise/dlp.resolved.csv\""],"metadata":{"id":"xwD0t8WzW5cF","executionInfo":{"status":"ok","timestamp":1706904054879,"user_tz":-60,"elapsed":233,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["#write_to_csv(resolved_acm, path_resolved_acm)"],"metadata":{"id":"nPOPDMExXhJF","executionInfo":{"status":"ok","timestamp":1706911481339,"user_tz":-60,"elapsed":252,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["def levenshtein_ratio(s1, s2):\n","    return ratio(s1.lower(), s2.lower())"],"metadata":{"id":"hjZ_nfhgn9qI","executionInfo":{"status":"ok","timestamp":1706911496244,"user_tz":-60,"elapsed":222,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["levenshtein_ratio(\"Tutorial Designing an Ultra Highly Available dbms\", \"An Ultra Highly Available DBMS\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLLn5LVfn9he","executionInfo":{"status":"ok","timestamp":1706911498677,"user_tz":-60,"elapsed":221,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"7cd7aa6a-f566-4374-8c8a-0f75a672e610"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.759493670886076"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["# Register the DataFrame as a temporary view\n","matches.createOrReplaceTempView(\"joined_data\")\n","\n","# Run SQL query to count occurrences of each blocking key\n","blocking_key_counts = spark.sql(\"\"\"\n","    SELECT new_blocking_key_df1, COUNT(*) AS count_new_blocking_key\n","    FROM joined_data\n","    GROUP BY new_blocking_key_df1\n","    ORDER BY count_new_blocking_key DESC\n","\"\"\")\n","\n","# Show the result\n","blocking_key_counts.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTAbq9M6V0cZ","executionInfo":{"status":"ok","timestamp":1706911542293,"user_tz":-60,"elapsed":2952,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}},"outputId":"c2a5513f-41d3-4a40-e068-978ea4a6a562"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----------------------+\n","|new_blocking_key_df1|count_new_blocking_key|\n","+--------------------+----------------------+\n","|          BonnetS02c|                     3|\n","|           BonnetS02|                     3|\n","|           ndezSXY03|                     2|\n","|          ndezSXY03c|                     2|\n","|           Aberer03c|                     2|\n","|         Bhashyam96c|                     2|\n","|            Aberer03|                     2|\n","|          Bhashyam96|                     2|\n","|       BouganimNPW03|                     1|\n","|           BrodieC99|                     1|\n","|       ChaudhuriDL04|                     1|\n","|        FlorescuKL97|                     1|\n","|      GunopulosMVV04|                     1|\n","|           KoudasS96|                     1|\n","|          PacittiS00|                     1|\n","|           Wiegand02|                     1|\n","|    BlausteinLMRST95|                     1|\n","|         DeWittGJW03|                     1|\n","|         FreytagLN99|                     1|\n","|           Ramanan03|                     1|\n","+--------------------+----------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RoIfU7JcV1jx","executionInfo":{"status":"aborted","timestamp":1706903614074,"user_tz":-60,"elapsed":23,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jwYRPEPdIcMY","executionInfo":{"status":"aborted","timestamp":1706903614074,"user_tz":-60,"elapsed":23,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wNimGYNKIcIT","executionInfo":{"status":"aborted","timestamp":1706903614074,"user_tz":-60,"elapsed":23,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DhFfTzJdIcE5","executionInfo":{"status":"aborted","timestamp":1706903614074,"user_tz":-60,"elapsed":22,"user":{"displayName":"Arjun Nepal","userId":"10283440571770609736"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSpZo0KkEHvqDzZldlVdwW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}